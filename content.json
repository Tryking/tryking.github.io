{"pages":[{"title":"404 - 消失在茫茫人海中","text":"很抱歉，您所访问的地址不存在: 您可以 返回主页 或者 查看所有文章 .article-header { padding: 0; padding-top: 26px; border-left: none; text-align: center; } .article-header:hover { border-left: none; } .article-title { font-size: 2.1em; } strong a { color: #747474; } .article-meta { display: none; } .share { display: none; } .ds-meta { display: none; } .player { margin-left: -10px; } .sign { text-align: right; font-style: italic; } #page-visit { display: none; } .center { text-align: center; height: 2.5em; font-weight: bold; } .article-entry hr { margin: 0; } .pic { text-align: center; margin: 0; } .pic br { display: none; } #container .article-info-post.article-info { display: none; } #container .article .article-title { padding: 0; }","link":"/404/index.html"},{"title":"about","text":"末日没有进行曲","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Privacy Policy","text":"Who we areOur website address is: http://123.207.124.221/wordpress. What personal data we collect and why we collect it评论When visitors leave comments on the site we collect the data shown in the comments form, and also the visitor’s IP address and browser user agent string to help spam detection. An anonymized string created from your email address (also called a hash) may be provided to the Gravatar service to see if you are using it. The Gravatar service privacy policy is available here: https://automattic.com/privacy/. After approval of your comment, your profile picture is visible to the public in the context of your comment. 媒体If you upload images to the website, you should avoid uploading images with embedded location data (EXIF GPS) included. Visitors to the website can download and extract any location data from images on the website. Contact formsCookiesIf you leave a comment on our site you may opt-in to saving your name, email address and website in cookies. These are for your convenience so that you do not have to fill in your details again when you leave another comment. These cookies will last for one year. If you have an account and you log in to this site, we will set a temporary cookie to determine if your browser accepts cookies. This cookie contains no personal data and is discarded when you close your browser. When you log in, we will also set up several cookies to save your login information and your screen display choices. Login cookies last for two days, and screen options cookies last for a year. If you select “Remember Me”, your login will persist for two weeks. If you log out of your account, the login cookies will be removed. If you edit or publish an article, an additional cookie will be saved in your browser. This cookie includes no personal data and simply indicates the post ID of the article you just edited. It expires after 1 day. Embedded content from other websitesArticles on this site may include embedded content (e.g. videos, images, articles, etc.). Embedded content from other websites behaves in the exact same way as if the visitor has visited the other website. These websites may collect data about you, use cookies, embed additional third-party tracking, and monitor your interaction with that embedded content, including tracking your interaction with the embedded content if you have an account and are logged in to that website. AnalyticsWho we share your data withHow long we retain your dataIf you leave a comment, the comment and its metadata are retained indefinitely. This is so we can recognize and approve any follow-up comments automatically instead of holding them in a moderation queue. For users that register on our website (if any), we also store the personal information they provide in their user profile. All users can see, edit, or delete their personal information at any time (except they cannot change their username). Website administrators can also see and edit that information. What rights you have over your dataIf you have an account on this site, or have left comments, you can request to receive an exported file of the personal data we hold about you, including any data you have provided to us. You can also request that we erase any personal data we hold about you. This does not include any data we are obliged to keep for administrative, legal, or security purposes. Where we send your dataVisitor comments may be checked through an automated spam detection service. Your contact informationAdditional informationHow we protect your dataWhat data breach procedures we have in placeWhat third parties we receive data fromWhat automated decision making and/or profiling we do with user dataIndustry regulatory disclosure requirements","link":"/privacy-policy/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"示例页面","text":"这是示范页面。页面和博客文章不同，它的位置是固定的，通常会在站点导航栏显示。很多用户都创建一个“关于”页面，向访客介绍自己。例如： 欢迎！我白天是个邮递员，晚上就是个有抱负的演员。这是我的博客。我住在天朝的帝都，有条叫做Jack的狗。 ……或这个： XYZ Doohickey公司成立于1971年，自从建立以来，我们一直向社会贡献着优秀doohickies。我们的公司总部位于天朝魔都，有着超过两千名员工，对魔都政府税收有着巨大贡献。 而您，作为一个WordPress用户，我们建议您访问控制板，删除本页面，然后添加您自己的页面。祝您使用愉快！","link":"/sample-page/index.html"}],"posts":[{"title":"Automatic Investment Plan","text":"Automatic Investment Plan USDT Time Price Amount Volume 2019-08-11 21:23:56 6.99 2000 CNY 286.123032 2019-09-25 06:45:01 7.23 2000 CNY 276.625172 2019-10-07 18:31:39 7.14 2500 CNY 350.140056 HT Time Price Amount Volume 2019-09-06 04:38:34 3.9334 10 2019-09-06 04:44:50 3.9266 5 2019-09-25 00:22 3.65 10 2019-10-07 18:39 3.093 100 BTC Time Price Amount Volume Tag 2019-08-11 20:06:49 80045 1000 CNY 0.012492 manual buy 2019-08-29 11:17:42 $9551.11 143.26665 0.015000 auto buy 2019-09-03 01:30:42 $10094.90 150.4234 0.015000 auto sell 2019-09-03 23:14:26 $10652.68 106.5268 0.010000 manual sell 2019-09-25 06:50 $8001.10 120.0165 0.015000 buy 2019-09-25 06:50 $8551.10 128.2665 0.015000 buy 2019-10-11 00:59 $8527 127.9050 0.015000 sell 2019-09-03 23:13:55 order: 9551.10 USDT buy 0.015 BTC (143.2665 USDT) 2019-08-29 23:24:29 order: 10094.90 USDT sell 0.015 BTC (151.4235 USDT) 2019-08-29 23:23:07 order: 9001.10 USDT buy 0.015 BTC (135.0165 USDT) 2019-08-16 06:22:35 order: 9551.11 USDT buy 0.015 BTC (143.26665000 USDT) 2019-08-11 21:41:25 order：9000.01 USDT buy 0.015 BTC (135.00015000 USDT) 标题：Automatic-Investment-Plan作者：末日没有进行曲链接：link时间：2019-08-11声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/11/Automatic-Investment-Plan/"},{"title":"Java字符串操作常用类的区别","text":"StringString类 在 Java 中被声明为final，所有的属性也都是final的。因此对于String的裁剪拼接等，都必须是要生成新的字符串。因此对于String的操作，效率比较低下。 StringBufferStringBuffer是线程安全的，它的线程安全是通过把各种修改数据的方法都加上 synchronized 关键字来实现的。StringBuffer的出现是为了克服String的这种效率低下的弊端，在它的底层使用了可修改的char数组注意1。在新建一个StringBuffer 对象时，默认创建的数组大小是16加上字符串的长度。因为如果数组过大会对空间造成浪费，数组过小，在我们进行具体的操作的时候，比如拼接等，空间又会不够。当空间不够的时候还需要对此扩容，扩容时又需要对原数组进行复制，会再次对性能造成影响。因此我们如果已经明确知道此StringBuffer会发生拼接，并且大概可以预计其最终拼接后的大小，就可以在new StringBuffer的时候对其大小进行指定，以防止不必要的开销。 StringBuilderStringBuilder的设计基本和StringBuffer是相同的，不同的是StringBuilder不是线程安全的，它的修改数据的方法没有加关键字 synchronized，效率会比StringBuffer更高。因此，如果是在单线程运行的情况下（一般都是此种场景），优先选择StringBuilder。StringBuffer 和 StringBuilder 都继承了 AbstractStringBuilder类。 注意 在JDK9以后已经换成了byte数组，因为Java中的 char 是两个 bytes 大小，拉丁语系语言的字符不需要太宽的 char，会对空间造成浪费。","link":"/2018/05/27/120/"},{"title":"Bootstrap - Modal 插件","text":"有时候我们可能需要在页面弹出一个对话框，或者传统的叫做 Popup Window 的东西。其实 Bootstrap 给我们提供了一个插件，可以非常方便的构造这几种东西，这个插件叫做 Modal。 引入 js 文件Bootstrap 的插件有很多都是独立成型的，并不需要依赖 Bootstrap 的所有 js 文件。想要使用 Modal 插件，我们既可以只引用单独的 modal.js 文件，还可以引包含 Bootstrap 的大部分内容的 js 文件 bootstrap.js 或 bootstrap.min.js。比如这里，我们直接引用 CDN，使用 bootstrap.min.js 文件。 12345678&lt;head&gt; &lt;title&gt;Bootstrap Example&lt;/title&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css\"&gt; &lt;script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js\"&gt;&lt;/script&gt;&lt;/head&gt; 创建一个 Modal下面我们创建一个 Modal，点击页面按钮直接跳出一个 Modal: 1234567891011121314151617181920212223&lt;!-- Trigger the modal with a button --&gt;&lt;button type=\"button\" class=\"btn btn-info btn-lg\" data-toggle=\"modal\" data-target=\"#myModal\"&gt;Open Modal&lt;/button&gt;&lt;!-- Modal --&gt;&lt;div id=\"myModal\" class=\"modal fade\" role=\"dialog\"&gt; &lt;div class=\"modal-dialog\"&gt; &lt;!-- Modal content--&gt; &lt;div class=\"modal-content\"&gt; &lt;div class=\"modal-header\"&gt; &lt;button type=\"button\" class=\"close\" data-dismiss=\"modal\"&gt;&amp;times;&lt;/button&gt; &lt;h4 class=\"modal-title\"&gt;Modal Header&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"modal-body\"&gt; &lt;p&gt;Some text in the modal.&lt;/p&gt; &lt;/div&gt; &lt;div class=\"modal-footer\"&gt; &lt;button type=\"button\" class=\"btn btn-default\" data-dismiss=\"modal\"&gt;Close&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 你可以在 W3C 提供的 工具 上进行尝试。 Trigger 部分在 Trigger 部分，我们使用了一个 “Open Modal” 的按钮来触发一个 Modal，在此按钮中需要加入两个 data-* 属性： data-toggle=&quot;modal&quot; 表明我们需要让其打开一个 modal。 data-target=&quot;#myModal&quot; 指向我们定义 modal 的 id。 Modal 部分 在 Modal 部分，在最外层的 &lt;div&gt; 部分，我们必须定义一个和在 Trigger 部分一样的 id，以让按钮能定位到此 Modal。 .modal 类将 &lt;div&gt; 的内容标识为 modal。 .fade 类会增加一个 modal 弹出及消失的渐变效果，如果不需要可以将此类去掉。 role=&quot;dialog&quot; 属性可以方便使用屏幕阅读器的人进行访问。 .modal-dialog 类设置了此 modal 适当的宽度和页面边的 margin。 Modal content 部分 拥有class=&quot;modal-content&quot; 的 &lt;div&gt; 定义了 modal 的样式（比如 border, background-color 等）。在此 &lt;div&gt; 中可以添加 modal 的 header, body 以及 footer 内容。 .modal-header 类用于定义 modal 的 header 的样式。header 中有一个属性为 data-dismiss=&quot;modal&quot; 的 &lt;button&gt;，点击它可以将 modal 关闭。.close 类定义了关闭按钮的样式。.modal-title 类以一个合适的行高定义了 header 的样式。 .modal-body 类用于定义 modal body 的样式。在这里面可以添加任何的 HTML 标记来生成 modal 的主体内容，比如你可以使用 paragraphs, images, videos 等。 .modal-footer 类用于定义 modal footer 的样式。默认情况下，此区域会右对齐。 更改 modal 大小在拥有 .modal-dialog 类的 &lt;div&gt; 中增加某些类可以控制 modal 的大小。 .modal-sm：small modal 12&gt; &lt;div class=&quot;modal-dialog modal-sm&quot;&gt;&gt; .modal-lg：large modal 12&gt; &lt;div class=&quot;modal-dialog modal-lg&quot;&gt;&gt; 默认情况下，modal 采用中等（medium）大小 更多用法，可参考 W3C教程：Bootstrap JS Modal。 标题：Bootstrap-Modal-插件作者：末日没有进行曲链接：link时间：2019-07-19声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/19/Bootstrap-Modal-插件/"},{"title":"Elasticsearch 查询语法(Kibana)）","text":"当我们使用 ELK 来分析日志时，需要根据条件过滤日志。其实在 Kibana 中用的查询语言就是 Elasticsearch 的查询语言，即使用 Lucene 的查询语法。 status 字段 包含 avtive 1status:active title 字段包含 quick 或 brown 1title:(quick OR brown) author 字段包含确切短语 “john smith” 1author:&quot;John Smith&quot; book.title, book.content 或 book.date 中的任何字段包含 quick 或 brown （注意我们需要使用反斜杠转义*） 1book.\\*:(quick OR brown) 字段 title 具有任何非空值 1_exists_:title 标题：Elasticsearch 查询语法(Kibana)）作者：末日没有进行曲链接：link时间：1566040157000声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/17/Elasticsearch-查询语法-Kibana-）/"},{"title":"Gradle 中的 compile, implementation, api 有什么区别？","text":"在 Gradle 中，我们引用一个 library 依赖的时候，一般会使用 compile, implementation, api 等这几种方式，你知道什么时候该用什么吗？ 区别首先说明，compile 虽然存在，但是它已经不被 Gradle 推荐使用。Gradel 3.0 中已经声明compile 应该被 api 和 implementation 替换。下面说 compile 和 api 的区别。 比如， 1dependencies { api 'commons-httpclient:commons-httpclient:3.1' implementation 'org.apache.commons:commons-lang3:3.5' } 使用 api 配置引用的依赖将会传递暴露给当前 library 的消费者，它会出现在消费者的编译类路径下。使用 implementation 配置引用的依赖不会暴露给当前 library 的消费者，因此它不会出现在消费者的编译类路径下。 使用 implementation 的有以下几点好处： 依赖不会再泄露到消费者的编译类路径下，因此将不会意外地发生传递依赖的问题。 因为减少了类路径的大小，因此编译速度更快。 当 implementation 发生改变时，消费者将不需要进行重新编译，因此编译次数变少了。 更简洁地发布：当和 maven-publish 插件一起使用时，Java 库生成的 POM 文件可以准确地区分针对该库进行编译所需的内容和在运行时针对该库所需的内容。（换句话说，不混合编译库本身所需的内容以及对库进行编译所需的内容） 如果你只在自己的应用模块中使用三方的库，其实你使用两者没有任何差别。但是如果你有一个包含相互依赖的复杂项目，或者你正在创建库时，你才能体会到这种差异。 举例下面举个例子。 假如我们有个项目有三个模块（module），A，B，C。它们的依赖关系如下： A -&gt; B -&gt; C，即 A 依赖于 B，B 依赖于 C。 在 C 中，有一个 CSecret 类， 123456public class CSecret { publis static String getSecret() { return \"password\"; }} 在 B 中有个方法需要使用 C 中的 CSecret 类， 123public class BContent { private static String content = CSecret.getSecret(); public static String getContent() { return \"My content: \" + content; }} 最后，在 A 中我们调用 B 中的 getContent 方法来获取我们需要的结果。 1234567public class ATest { public static void main(String args) { BContent bContent = new BContent(); System.out.println(\"Get bContent: \" + bContent.getContent()); }} 现在，我们针对依赖来讨论一下。 A 需要消费 B，因此在 A 的 build.gradle 中需要使用 implementation。 1dependencies { implementation project(':B') } 那么，在 B 的 build.gradle 中需要怎么写呢？ 我们有以下三种方式可供选择： 1dependencies { // 方式 #1 implementation project(&apos;:C&apos;) // 方式 #2 compile project(&apos;:C&apos;) // 方式 #3 api project(&apos;:C&apos;) } 如果你使用 compile 或者 api，那我们在 A 模块中就可以直接访问到 C 模块，即我们可以直接调用 C 中的 CSecret，显然这不是我们需要的。 假如我们使用 implementation，那么 C 模块将不会对 A 暴露，这才是我们需要的结果。 总结这下你应该知道我们该如何选择了吧？ 当我们需要给消费者暴露内部依赖的时候，使用 api 或者 compile。（complie已经不被推荐使用了，因此我们最好使用 api） 当我们不需要暴露给消费者我们内部依赖的时候，使用 implementation。其实，大多数情况下，我们应该使用的就是这个。 标题：Title作者：末日没有进行曲链接：link时间：2019-09-01声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/09/01/Gradle-中的-compile-implementation-api-有什么区别？/"},{"title":"Gradle - 创建 Gradle 构建","text":"根据此教程，你可以创建一个小型 Gradle 项目，这里面会涉及一些基础的 Gradle 命令，你可以对 Gradle 是如何管理项目的有个深刻的理解。 你需要准备 大约 11 分钟的时间 一个终端工具（Terminal） 一个 Java 运行时环境（JRE）或者 Java 开发工具（JDK），Java 版本需要在 1.8 以上。 一个 Gradle 发布版本，版本最好在 4.10.3 及以上。 初始化一个项目12&gt; mkdir basic-demo&gt; cd basic-demo 现在就可以使用 Gradle 的 init 命令生成一个简单的项目了。我们将探索生成的所有东西，以便于你能知道发生了什么。 12345&gt; gradle initStarting a Gradle Daemon (subsequent builds will be faster)BUILD SUCCESSFUL in 3s2 actionable tasks: 2 executed 运行完这个命令后应该会显示“BUILD SUCCESSFUL”，并且会生成以下 “空” 项目。如果没有执行成功，请检查一下 Gradle 是否正确安装了，并且你要确保你配置了正确的 JAVA_HOME环境。 Gradle 生成了如下内容： Groovy 12345678├── build.gradle ├── gradle│ └── wrapper│ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── gradlew ├── gradlew.bat └── settings.gradle build.gradle 用于配置当前项目的 Gradle 构建脚本。 gradle-wrapper.jar 是 Gradle Wrapper 的可执行 JAR。 gradle-wrapper.properties 是 Gradle Wrapper 的配置内容。 gradlew是类 Unix 系统的 Gradle Wrapper 脚本。 gradlew.bat是 Windows 的Gradle Wrapper 脚本。 settings.gradle 是 Gradle 用于配置 Gradle 构建的设置脚本。 好啦！就这样，我们完成了基本的指导，但是你可能还想知道如何在项目中使用 Gradle。我们继续。 创建一个任务Gradle 使用基于 Groovy 或者 Kotlin 的语言，给我们提供了一系列的 API，用于创建和配置任务。一个 Project 包含一系列的Tasks，每个 task 都会执行一些基本的操作。 Gradle 附带了一个可以在您自己的项目中配置的任务库。例如，有一个核心的 type 叫做 Copy，它会从一个地方复制文件到另一个地方。Copy task 非常有用（可以参考 see the documentation 获取详情），但是在这里，我们简化一下，执行以下步骤： 创建一个文件夹 src。 在 src 文件夹下增加一个文件 myfile.txt 。文件内容你可以随便写（也可以是空的），但是为了方便我们增加一行 Hello, World! 在里面。 在 build 文件中定义一个 Copy (注意大小写)类型的任务copy，复制 src 文件夹到一个新的文件夹 dest 中。（我们不需要手动创建 dest 文件夹，task 会自动帮我们创建。） build.gradle 1234task copy(type: Copy, group: \"Custom\", description: \"Copies sources to the dest directory\"){ from \"src\" into \"dest\"} 其中，group 和 description你可以随便写。你也可以省略，但是省略后在后面的repost task 中这些内容也会省略。 现在执行一下 copy task。 12345❯ ./gradlew copy&gt; Task :copyBUILD SUCCESSFUL in 0s1 actionable task: 1 executed 检查一下，在 dest 目录中生成了一个新的myfile.txt文件，它的内容和我们在 src 目录中的文件的内容是一样的。 应用插件 pluginGradle 提供了一系列的插件，有许多插件在 the Gradle plugin portal 中可以找到。该发行版附带的其中一个插件是 base 插件。结合名为 Zip 的一个核心 type，你可以使创建一个 zip 压缩档，并且可以指定名字和位置。 使用plugins语法增加 base 插件到你的 build 脚本文件中。请确保在文件的最上面增加plugins{}块。 build.gradle 12345plugins { id \"base\"}... rest of the build file ... 然后可以增加一个任务对 src 目录创建一个 zip 压缩档。 build.gradle 1234task zip(type: Zip, group: \"Archive\", description: \"Archives sources in a zip file\"){ from \"src\" setArchiveName \"basic-demo-1.0.zip\"} base 插件和 settings 一起工作可以在 build/distributions 文件夹下创建一个名为 “basic-demo-1.0.zip” 的压缩文件。 然后，运行新的 zip task，可以看到我们期望的 zip 压缩文件已经生成了。 12345❯ ./gradlew zip&gt; Task :zipBUILD SUCCESSFUL in 0s1 actionable task: 1 executed 继续探索并调试你的 build我们还能使用 Gradle 在我们的新项目中做什么呢？这儿有一份完整的列表可以查看: reference to the command-line interface。 发现可用的 taskstasks 命令会列出你可以调用的 Gradle tasks，其中包含 base 插件中的，和你自己增加定制的。 1❯ ./gradlew tasks 分析调试你的 buildGradle 还提供了一个基于 Web 的丰富的构建视图，称为构建扫描（build scan）。 使用 --scan 参数或者在项目中显式应用 scan 插件，就可以免费在 scans.gradle.com 上创建构建扫描。将构建扫描发布到 scans.gradle.com 上会将此数据传输到 Gradle 服务器。想要将你的数据放在你自己的服务器上，请查看 Gradle Enterprise。 当执行 task 的时候可以尝试使用 --scan 参数创建一个 build scan。 12345678910❯ ./gradlew zip --scanBUILD SUCCESSFUL in 0s1 actionable task: 1 up-to-datePublishing a build scan to scans.gradle.com requires accepting the Terms of Service defined at https://scans.gradle.com/terms-of-service. Do you accept these terms? [yes, no]Gradle Cloud Services license agreement accepted.Publishing build scan...https://gradle.com/s/repnge6srr5qs 发现可用的配置properties 命令会展示关于你的项目的属性。 1❯ ./gradlew properties 输出会比较多，这里我们列出一小部分可用的配置。 123456789101112131415&gt; Task :properties------------------------------------------------------------Root project------------------------------------------------------------buildDir: /Users/.../basic-demo/buildbuildFile: /Users/.../basic-demo/build.gradledescription: nullgroup:name: basic-demoprojectDir: /Users/.../basic-demoversion: unspecifiedBUILD SUCCESSFUL 项目的 name 默认适合目录名相同的。你也可以指定 group 和 version 属性，但是现在我们使用的是它们的默认值。 buildFile 属性是 build 脚本的全路径，它默认使用的是项目目录。 我们可以改变许多属性。例如，我们可以增加以下内容到 build 脚本文件中，重新执行 gradle properties。 12description = &quot;A trivial Gradle build&quot;version = &quot;1.0&quot; 下一步恭喜！我们已经创建了一个新的 Gradle build，并且学习了如何检查 Gradle build。 如果碰巧你也想要在特定的平台上创建一个 library 或者 application，你可以参照下面的指导。 Building Android Apps Building Java Libraries Building Kotlin JVM Libraries Building C++ Executables Building Groovy Libraries Building Scala Libraries 你还可以在 sample Gradle builds on GitHub 查看更多构建示例。 声明：本文为官方文档的翻译。Creating New Gradle Builds","link":"/2019/07/02/Gradle-创建-Gradle-构建/"},{"title":"Gradle - 构建 Java 应用程序","text":"此教程会演示如何使用 Gradle 的 Build Init 插件创建遵循 Gradle 约定的新 Java 应用程序。 你需要准备 大约 9 分钟的时间 一个文本编辑器 一个命令提示符 JDK 8 或者更高版本 版本为 5.4.1 或者更高的 Gradle 分发版 查看用户手册Gradle 默认有一个名为 Build Init 的内置插件，在 Gradle 用户手册 中有记录。该插件提供了一个名为 init 的任务，用于生成项目。该插件还会使用 wrapper（也是内置的）任务来创建 Gradle 包装器脚本 gradlew。 步骤第一步需要给新项目创建一个文件夹，然后进入该目录。 12$ mkdir demo$ cd demo 运行 init 任务进入新项目的目录后，运行 init 任务，当提示的时候选择 java-application 项目类型。其他问题，直接按 enter 使用默认的值即可。 1234567891011121314151617181920212223242526272829303132$ gradle initStarting a Gradle Daemon (subsequent builds will be faster)Select type of project to generate: 1: basic 2: cpp-application 3: cpp-library 4: groovy-application 5: groovy-library 6: java-application 7: java-library 8: kotlin-application 9: kotlin-library 10: scala-libraryEnter selection (default: basic) [1..10] 6Select build script DSL: 1: groovy 2: kotlinEnter selection (default: groovy) [1..2] Select test framework: 1: junit 2: testng 3: spockEnter selection (default: junit) [1..3] Project name (default: demo): Source package (default: demo): BUILD SUCCESSFUL in 23s2 actionable tasks: 2 executed 如果你喜欢使用 Kotlin 语言，你也可以选择 kotlin 构建脚本 DSL。 init 任务首先会运行 wrapper 任务，它将生成 gradlew 和 gradlew.bat 包装脚本。然后它会创建一个如下所示结构的新项目： 12345678910111213141516171819├── build.gradle├── gradle 1️⃣│ └── wrapper│ ├── gradle-wrapper.jar│ └── gradle-wrapper.properties├── gradlew├── gradlew.bat├── settings.gradle└── src ├── main │ ├── java 2️⃣ │ │ └── demo │ │ └── App.java │ └── resources └── test 3️⃣ ├── java │ └── demo │ └── AppTest.java └── resources 1️⃣：生成的包含 wrapper 文件的文件夹 2️⃣：默认的 Java source 文件夹 3️⃣：默认的 Java test 文件夹 查看生成的项目文件settings.gradle 文件中有很多注释行，但是只有一个活动行。 settings.gradle1rootProject.name = 'demo' 这会将根项目的名称设置为 demo，如果不设置此值，默认会将目录名作为项目名。 生成的 build.gradle 文件也有许多注释。此处将活动行列出（注意依赖项的版本号可能会在更高版本的 Gradle 中有所更新）。 build.gradle1234567891011121314151617plugins { id 'java' id 'application'}repositories { jcenter() 1️⃣}dependencies { implementation 'com.google.guava:guava:27.0.1-jre' 2️⃣ testImplementation 'junit:junit:4.12' 3️⃣}mainClassName = 'demo.App' 4️⃣ 1️⃣：公共 Bintray Artifactory 存储库. 2️⃣：Google Guava library 3️⃣：JUnit testing library 4️⃣：含有 “main” 方法的类（使用 Application 插件）。 构建文件增加了 java 和 application 插件。java 插件用于支持 Java 程序，application 插件让你指定一个具有 main 方法的类，该方法可以通过命令行中的构建来执行。在这个示例中，主类的名称是 App。 文件 src/main/java/demo/App.java 的内容如下： src/main/java/demo/App.java1234567891011package demo;public class App { public String getGreeting() { return \"Hello world.\"; } public static void main(String[] args) { 1️⃣ System.out.println(new App().getGreeting()); }} 1️⃣：被 Application 插件的 run 任务调用。 文件 src/test/java/demo/AppTest.java 的内容如下： src/test/java/demo/AppTest.java1234567891011package demo;import org.junit.Test;import static org.junit.Assert.*;public class AppTest { @Test public void testAppHasAGreeting() { App classUnderTest = new App(); assertNotNull(\"app should have a greeting\", classUnderTest.getGreeting()); }} 生成的 test 类有一个用 JUnit 的 @Test 注释的测试。test 会实例化 App 类，调用 getGreeting 方法，然后检查返回的值是否为 null。 执行构建想要构建项目，需要执行 build 任务。你可以使用常规的 gradle 命令，但是当一个项目包含一个 wrapper 脚本时，用它来代替执行是更好地选择。 123456789101112131415161718$ ./gradlew build&gt; Task :compileJava&gt; Task :processResources NO-SOURCE&gt; Task :classes&gt; Task :jar&gt; Task :startScripts&gt; Task :distTar&gt; Task :distZip&gt; Task :assemble&gt; Task :compileTestJava&gt; Task :processTestResources NO-SOURCE&gt; Task :testClasses&gt; Task :test&gt; Task :check&gt; Task :buildBUILD SUCCESSFUL8 actionable tasks: 8 executed 当你第一次运行 wrapper 脚本 gradlew 时，可能需要花费一些时间等待该 gradle 版本下载并存储到你的 ~/.gradle/warpper/dists 文件夹中。 当你第一次运行构建时，Gradle 将检查在你的 ~/.gradle 目录中是否已经有 Guava 和 JUnit 库的缓存。如果没有，这些库将被下载并且存储在缓存目录下。下一次你运行这个构建的时候，缓存版本将被使用。此构建任务将会编译 classes，运行 tests，然后生成一个 test 报表。 你可以打开 HTML 输出文件查看 test 报表，报表在 build/reports/tests/test/index.html 文件中。 一个简单的报表如下： 运行程序因为 Gradle 构建使用了 Application 插件，因此你可以在命令行中运行 application。首先，使用 tasks 任务查看有什么任务被添加进了插件。 12345678910111213$ ./gradlew tasks&gt; Task :tasks------------------------------------------------------------Tasks runnable from root project------------------------------------------------------------Application tasks-----------------run - Runs this project as a JVM application// ... many other tasks ... run task 会告诉 Gradle 让其执行被分配了 mainClassName 属性的类中的 main 方法。 1234567./gradlew run&gt; Task :runHello world.BUILD SUCCESSFUL in 0s2 actionable tasks: 1 executed, 1 up-to-date 总结现在你使用 Gradle 的 build init 插件生成了一个新的 Java 项目，在此过程中，你看到了： 如何生成一个 Java 应用。 如何生成构建文件以及了解 Java 文件的结构。 如何运行构建以及查看 test 报表。 如何使用 Application 插件的 run task 执行 Java 应用程序。 声明：本文为官方文档的翻译。Building Java Applications 标题：Gradle - 构建 Java 应用程序作者：末日没有进行曲链接：https://dengkaiting.com/2019/07/14/Gradle-构建-Java-应用程序时间：2019-07-11声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/14/Gradle-构建-Java-应用程序/"},{"title":"Gson - 你真的懂吗？","text":"平时使用 Gson 可能也就使用下基本功能，但是你对 Gson 真的了解吗？ 对于含有内部类的嵌套类序列化对于静态嵌套类， Gson 可以非常容易地进行序列化。但是对于纯内部类，Gson 不能进行反序列化，因为它们的无参构造函数还要对反序列化时不可用的 Object 进行引用。比如，当反序列化 Hand 时，需要引用 Person，但是此时 Person 不能被引用。 12345678public class Person { private Hand hand; private class Hand { private String thumb; }} 解决办法有两种： 指定内部类为静态类， 给内部类提供一个自定义的实例生成器。 123456789public class InstanceCreatorForHand implements InstanceCreator&lt;Person.Hand&gt; { private final Person person; public InstanceCreatorForHand(Person person) { this.person = person; } public Person.Hand createInstance(Type type) { return person.new Hand(); }} 数组实践 序列化 123456Gson gson = new Gson();int[] ints = {1, 2, 3, 4, 5};String[] strings = {\"abc\", \"def\", \"ghi\"};System.out.println(gson.toJson(ints));System.out.println(gson.toJson(strings)); print: [1,2,3,4,5] [“abc”,”def”,”ghi”] 反序列化 1int[] ints2 = gson.fromJson(\"[1,2,3,4,5]\", int[].class); 集合实践 序列化 1234Gson gson = new Gson();Collection&lt;Integer&gt; ints = List.of(1, 2, 3, 4, 5);String json = gson.toJson(ints); print:[1,2,3,4,5] 反序列化 12Type collectionType = new TypeToken&lt;Collection&lt;Integer&gt;&gt;(){}.getType();Collection&lt;Integer&gt; ints2 = gson.fromJson(json, collectionType); 集合局限性 可以序列化任意类型的集合，但是不能从其进行反序列化。 因为没有方法指定结果对象的类型。 当反序列化的时候，集合必须是特定的泛型类型。 上面提到的这些都是有意义的，如果遵循良好的 Java 编码规范，基本不会出现问题。 JsonElement该类为一个抽象类，像 JsonArray, JsonObject, JsonPrimitive 以及 JsonNull 都继承自它。 当我们想要判定某个 Json 是否为 JsonObject 时，可以用 123public boolean isJsonObject() { return this instanceof JsonObject;} 此方法来实现，其他三个实现类也有同样实现。 我们还可以使用 getAsJsonObject() 方法将当前 JsonElement 以 JsonObject 形式返回，如果它不是 JsonObject，则报错。其他三个同理。 使用示例基本使用123456789101112131415161718192021222324252627public class GsonTest { public static void main(String[] args) { GsonTest gsonTest = new GsonTest(); JsonElement jsonObject = gsonTest.getJsonObject(\"{\\\"A\\\":\\\"B\\\"}\"); JsonObject asJsonObject = jsonObject.getAsJsonObject(); System.out.println(asJsonObject); JsonArray asJsonArray = jsonObject.getAsJsonArray(); // 报错 System.out.println(asJsonArray); Gson gson = new Gson(); JsonArray aaa = gson.fromJson(\"[\\\"a\\\",\\\"aa\\\"]\", JsonArray.class); System.out.println(aaa); JsonObject bbb = gson.fromJson(\"[\\\"a\\\",\\\"aa\\\"]\", JsonObject.class); //报错 } private JsonElement getJsonObject(String s) { try { Gson gson = new Gson(); JsonElement element = gson.fromJson(s, JsonElement.class); return element; } catch (Exception e) { e.printStackTrace(); } return null; }} 解析 JsonArray1234567891011121314151617@SuppressWarnings(\"unchecked\") public &lt;T&gt; Object parseAsArrayList(String serializedData, T type) { ArrayList&lt;T&gt; newArray = new ArrayList&lt;T&gt;(); Gson gson = new Gson(); JsonElement json = new JsonParser().parse(serializedData); JsonArray array = json.getAsJsonArray(); Iterator&lt;JsonElement&gt; iterator = array.iterator(); while (iterator.hasNext()) { JsonElement json2 = iterator.next(); T object = (T) gson.fromJson(json2, (Class&lt;?&gt;) type); newArray.add(object); } return newArray; } 标题：[Gson - 你真的懂吗？](https://dengkaiting.com/2019/07/24/Gson - 你真的懂吗？/)作者：末日没有进行曲链接：link时间：2019-07-24声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/24/Gson-你真的懂吗？/"},{"title":"Json Schema 是什么？","text":"简单说，Json Schema 其实就是一个标准的 Json 串，它以一个 Json 串来描述我们需要的数据规范，并且支持注释以及验证 Json 文档，即我们可以用 Json Schema 来验证所给的 Json 串是否满足我们需要的数据格式规范。 同样能用来表示数据的还有一种格式 XML，为什么 Json Schema 偏偏要用 Json 来进行表示数据呢？对于机器，其实这两种方式是没有区别的，机器只要你把标准给了它，它都能用很快的速度识别出来（相对于我们人），但是 XML 对于人识别就太不友好了。比如，假设我们需要描述一个班级的两个人： 对于 XML： 1234567891011121314&lt;class&gt; &lt;name&gt;实验1班&lt;/name&gt; &lt;no&gt;1801&lt;/no&gt; &lt;students&gt; &lt;student&gt; &lt;name&gt;张三&lt;/name&gt; &lt;sex&gt;女&lt;/sex&gt; &lt;/student&gt; &lt;student&gt; &lt;name&gt;李四&lt;/name&gt; &lt;sex&gt;男&lt;/sex&gt; &lt;/student&gt; &lt;/students&gt;&lt;/class&gt; 使用 Json： 123456789101112131415161718{ &quot;class&quot;: { &quot;name&quot;: &quot;实验1班&quot;, &quot;no&quot;: &quot;1801&quot;, &quot;students&quot;: { &quot;student&quot;: [ { &quot;name&quot;: &quot;张三&quot;, &quot;sex&quot;: &quot;女&quot; }, { &quot;name&quot;: &quot;李四&quot;, &quot;sex&quot;: &quot;男&quot; } ] } }} 有没有觉得 Json 立马秒杀 XML？这里可能感觉还不是很明显，这是因为层级比较少，层级再多之后，Json 的优势立马就显现出来了。 Json Schema 在我们平时的工作中最常用的有两个，一个就是上面说的用于验证 Json 串的合法性；另一个就是用于定义我们的 API，定义好 API 后，我们可以直接用工具生成我们的 API，这样利于我们对 API 的维护。 验证 Json 串的合法性比如，我们定义的 Json Schema 为： 12345678910111213141516171819202122{ &quot;$schema&quot;: &quot;http://json-schema.org/draft-04/schema#&quot;, &quot;title&quot;: &quot;Product&quot;, &quot;description&quot;: &quot;A product from Acme&apos;s catalog&quot;, &quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: { &quot;id&quot;: { &quot;description&quot;: &quot;The unique identifier for a product&quot;, &quot;type&quot;: &quot;integer&quot; }, &quot;name&quot;: { &quot;description&quot;: &quot;Name of the product&quot;, &quot;type&quot;: &quot;string&quot; }, &quot;price&quot;: { &quot;type&quot;: &quot;number&quot;, &quot;minimum&quot;: 0, &quot;exclusiveMinimum&quot;: true } }, &quot;required&quot;: [&quot;id&quot;, &quot;name&quot;, &quot;price&quot;]} 在上述 Json Schema 中 最上面的 $shcema 是一个关键字，它表示我们所定义的 Schema 和 http://json-schema.org/draft-04/schema#（Json Schema 的 v4 规范）是一致的 title 指的是标题。 description 用于描述我们所定义的 Schema，上述表明我们定义的是一个来自 Acme 目录的商品。 type 表示我们定义的是一个 object 对象。 properties 中就是 Schema 的属性了，这里面的是核心。我们可以看到该 Schema 一共有三个属性，分别是 id(integer), name(string), prince(number)。 最后的 required 表明三个属性都是必须的。 给定了上述 Schema，我们就可以验证给定的 Json 是否是合规的了。比如： 1234{ &quot;id&quot;: 1, &quot;name&quot;: &quot;watermelon&quot;} 显然，这个 Json 缺少了一个属性 price，所以它不合规。 12345{ &quot;id&quot;: 1, &quot;name&quot;: [&quot;knife&quot;, &quot;spoon&quot;], &quot;price&quot;: 4} 这个 Json 的 name 属性是一个数组，我们上面规定 name 只能是 String，显然这个也不是合规的。 12345{ &quot;id&quot;: 1, &quot;name&quot;: &quot;watermelon&quot;, &quot;price&quot;: 4} 这个，就满足了上面定义的所有规则，因此这个是一个合规的 Json。 定义 API其实，使用我们上面的 Json Schema 便能进行 API 的定义了，只不过是定义 API 的话可能还需要更多的支持。比如，对于 Java，我们需要能实现 extend 等关键字的支持，还需要能进行枚举 enum 类型等的定义。这里只简单使用上述的内容显然不够了，我们还需要扩充一些关键字的使用。 目前，大家使用最多的将 Json Schema 转换为 Java Bean 的一个库是 jsonschema2pojo，后面我将依托这个库支持的内容对 Json Schema 的格式进行深入解析，此库支持的也是比较通用的。","link":"/2019/06/25/Json-Schema-是什么？/"},{"title":"Kubernetes - 基础知识","text":"你知道如何创建一个 Kubernetes 集群吗？ 创建一个 Kubernetes 集群创建一个集群首先我们需要安装 minikube 使用命令 minikube version，检查 minikube 是否安装成功。 然后我们可以使用命令 minikube start 启动 minikube。 等待 minikube 启动后，一个 Kubernetes 集群就已经运行起来了。 集群版本为了和 Kubernetes 进行交互，我们需要使用 kubectl 命令行。为了检测 kubectl 是否已经成功安装，我们可以使用命令 kubectl version. 123$ kubectl versionClient Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.3\", GitCommit:\"06ad960bfd03b39c8310aaf92d1e7c12ce618213\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T18:14:22Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}Server Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.3\", GitCommit:\"06ad960bfd03b39c8310aaf92d1e7c12ce618213\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T18:07:13Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"} 根据上面的信息，我们可以看到 kubectl 已经配置成功了。 其中 Client version 指的是 kubectl 的版本，Server version 指的是安装在 master 节点的 Kubernetes 的版本。 查看集群详情我们还可以查看集群的详情。 kubectl cluster-info 查看集群的详情。 kubectl get nodes 这个命令展示了可以用于托管我们应用程序的所有节点。 部署一个 APP 应用一个 Pod 是 Kubernetes 应用中一个基本的执行单元。每个 Pod 都代表运行在你的集群中工作负载的一部分。 部署我们的 APP 应用Kubernetes 部署 APP 的命令是 kubectl create deployment。我们需要提供部署的名字和 APP 的镜像位置（包含镜像在外部 Docker hub 仓库的全路径），例如： kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 部署完后，我们可以使用以下命令获取我们所有已经部署过的 APP。 kubectl get deployments 查看我们的 APP 应用运行在 Kubernetes 内部的 Pods 相当于运行在一个私有的、独立的网络中。默认情况下，各个 Pod 之间以及在相同 Kubernetes 集群中的服务是可见的，但是对于外部网络不可见。我们使用 kubectl的命令可以通过 API endpoint 来和我们的应用进行交互。 后面我们会学习如何暴露应用给外部的 Kubernetes 集群。 kubectl proxy 命令可以创建一个代理，这将可以把通信转发到集群内的私有网络。当按下 Control+C 时，代理可以被终端。当代理工作的时候，界面不会有任何输出。 创建好代理后，我们就可以直接访问我们刚刚部署的应用服务了。 探索应用当我们创建一个应用部署时，Kubernetes 会创建一个 Pod 来管理应用实例。Pod 是 Kubernates 用来表示拥有一个或多个应用实例容器（比如 docker 或者 rkt）的一个组的概念，这些容器之间共享资源。这些资源包括： 共享存储，作为存储卷 网络，作为一个独立的集群 IP 地址 有关如何运行每个容器的信息，比如容器镜像版本或者要使用特定的端口 Pod 为特定于应用程序的 “逻辑主机” 建模，并且可以包含相对紧密耦合的不同应用程序容器。例如，一个 Pod 可能同时包含带有 Node.js 应用程序的容器以及一个不同的容器，该容器将提供要有 Node.js Web 服务器发布的数据。 Pod 中的容器之间共享一个 IP 地址和端口空间，它们始终位于同一位置并共同调度，并运行在同一节点的共享上线文中。 Pod 是 Kubernetes 平台上的原子单元。当我们在 Kubernetes 上创建一个部署时，部署会创建包含一些容器的一个 Pod（与直接创建容器相对立）。每个 Pod 都绑定到计划的节点上，并保持在那里，直到终止（根据重新启动策略）或删除为止。如果节点发生故障，Kubernetes会在集群中其他可用节点上调度相同的 Pod。 NodesPod 始终运行在 Node 上。Node 是 Kubernetes 中的工作机，可以是虚拟机或者物理机，这具体取决于集群。每个 Node由主 Node 管理。一个 Node 可以有多个 Pod， Kubernetes 中的 Master 会自动处理跨集群中所有 Node 调度 Pod 的过程。Master 的自动调节会考虑每个 Node 上的可用资源。 每个 Kubernetes Node 至少会运行： Kubelet， 一个负责 Kubernetes Master 与 Node 之间通信的组件；它会管理 Pod 和在机器上运行的容器。 容器运行时（比如 Docker, rkt）。它负责从注册表中提取容器镜像，解压缩容器并运行应用程序。 使用 Kubectl 进行故障排查常用的 Kubectl 命令有： kubectl get 列出资源 kubectl describe 显示有关资源的详细信息 kubectl log 从容器中的容器中打印日志 kubectl exec 在容器中的容器上执行命令 我们可以使用这些命令来查看应用程序的部署时间，它们的当前状态，运行的位置以及它们的配置。 使用服务公开应用Kubernetes 服务概述Kubernetes 中的 Pods 是会死亡的。实际上 Pods 是有生命周期的。当一个工作 Node 死亡了，运行在其上的 Pods就跟着丢失了。然后 ReplicaSet 可能会通过创建新的 Pods 来动态地将集群驱动回所需的状态，以保持应用程序正常运行。现在，假设有一个具有3个副本的图像处理后端，这些副本是可以交换的。但是对于前段系统来说，我们不应该关心后端的副本，即使 Pod 丢失并重新创建。也就是说，Kubernetes 集群中的每个 Pod 都有一个唯一的 IP 地址，即使是同一个节点上的 Pod 也是一样，因此我们需要一种自动协调 Pod 之前的方法，以便应用程序能持续运行。 Kubernetes 中的服务是一种抽象，它定义了 Pod 的逻辑集合和访问 Pod 的策略。服务使从属 Pod 之间的松耦合成为可能。像所有 Kubernetes 对象一样，使用 YAML 或 JSON 定义服务。服务所针对的 Pod 集合通常由 LabelSelector 决定。 尽管每个 Pod 都有一个唯一的 IP 地址，但是如果没有 Service，这些 IP 不会暴露在集群外部。Service 允许应用程序接收流量。通过 type 在 ServiceSpec 中指定可以以不同的方式公开服务： ClusterIP（默认）- 在群集的内部 IP 上公开服务，这种类型使得只能从群集内访问服务。 NodePort - 使用 NAT 在群集中每个选定节点的相同端口上公开服务。使得可以使用 &lt;NodeIP&gt;:&lt;NodePort&gt;从群集外部访问服务。它是 ClusterIP的超集。 LoadBalancer - 在当前云中创建一个外部负载平衡器（如果支持），并为该服务分配一个固定的外部 IP。它是 NodePort 的超集。 ExternalName - externalName 通过返回具有该名称的 CNAME 记录，使用任意名称（在规定范围中指定）公开服务。它不使用代理，这种类型需要 v1.7 以上的 kube-dns。 Services 和 LabelsService 在一组 Pod 之前路由流量。Service 是允许 Pod 在 Kubernetes 中死亡和复制交叉而又不影响应用程序的一个概念。Kubernetes Services 处理在依赖 Pod （例如应用程序中的前端和后端组件）之间的发现和路由。 Service通过 labels 和 selectors来匹配一组 Pods，这是一组原语，其允许对 Kubernetes 中的对象进行逻辑操作。labels 是附加在对象上的键值对，可以多种方式使用： 指定用于开发，测试和生产环境的对象 嵌入版本标签 使用 label 对对象进行分类 labels 可以在创建时或者创建完成后附加到对象，并且可以随时对它们进行修改。 运行应用程序的多个实例扩缩（Scaling）应用程序在之前的模块中，我们创建了一个 Deployment，然后通过 Service 让其可以公开访问。Deployment 仅为跑这个应用程序创建了一个 Pod。当流量增加时，我们需要扩容应用程序以满足用户需求。 扩缩（Scaling）是通过改变 Deployment 中的副本数量来实现的。 在运行 kubectl run 命令时，可以通过设置 –replicas 参数来设置 Deploy 的副本数量。 扩缩概述扩缩 Deployment 将创建新的 Pods，并将资源调度请求分配到有可用资源的节点上，收缩会将 Pods 的数量减少至所需的状态。 Kubernetes 还支持 Pods 的自动缩放。 运行应用程序的多个实例需要在它们之间分配流量。服务（Service）有一种负载均衡器类型，它可以将网络流量均衡分配到外部可以访问的 Pods 上。Service 将会一直通过端点来监视 Pods 的运行，保证流量只分配到可用的 Pods 上。 指定滚动更新更新应用程序用户希望应用程序始终可用，而开发人员则需要每天多次部署它们的新版本。在 Kubernetes 中，这些可以通过滚动更新（Rolling Updates）来完成。滚动更新允许通过使用新的实例逐步更新 Pod 实例，零停机进行 Deployment 更新。新的 Pod 将在具有可用资源的 Node 上进行调度。 在前面的模块中，我们将应用程序扩展为运行多个实例。这是在不影响应用程序可用性的情况下执行更新的要求。默认情况下，更新期间不可用的 Pod 的最大值和可以创建 Pod 数都是 1 。这两个选项都可以配置为（Pod）数字或百分比。在 Kubernetes 中，更新时经过版本控制的，任何 Deployment 更新都可以恢复到以前的（稳定）版本。 标题：Kubernetes - 创建一个 Kubernetes 集群作者：末日没有进行曲链接：link时间：2020-03-15声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/03/15/Kubernetes-基础知识/"},{"title":"Life record","text":"Record October Date Rope Skipping Squat Other 1 2 3 4 5(S) 6 7 21:59 - 14mins - 1100 8 22:25 - 13mins - 1100 9 10 11 23:00 - 14mins - 1000 12(S) 13 14 15 16 17 18 19(S) 20 21 22 23 24 25 26(S) 27 28 29 30 31 September Date Rope Skipping Squat Other 1 2 3 4 5 6 7(S) 22:54 - 16mins - 1000 8 21:47 - 17mins - 1100 9 10 11 00:11 - 5mins - 600 badminton 12 13 14(S) 15 16 17 badminton 18 22:14 - 15mins - 1200 19 22:14 - 17mins - 1500 20 21(S) 600 22 1100 23 1100 24 badminton 25 26 27 22:19 - 19mins - 1200 28(S) 21:42 - 15mins - 1100 29 30 August Date Rope Skipping Squat Other 1 8:00 - 35*3 2 badminton 3(S) 21:20 - 15mins - 800 4 19:30 - 18mins - 1000 7:30 - 35*3 5 21:50 - 15mins - 1000 6 7:10 - 35*3 7 22:00 - 13mins - 1000 8 21:54 - 16mins - 1100 7:00 - 35*2 9 badminton barbecue 10(S) 21:50 - 17mins - 1000 17:00 - 35*3 11 22:00 - 17mins - 1100 12 21:54 - 16mins - 1100 6:35 - 35*3 13 badminton 14 21:29 - 6mins - 500 15 16 17(S) 22:01 - 9mins - 800 18 22:06 - 15mins - 1000 19 22:27 - 17mins - 1100 20 21 23:30 - 14mins - 1100 22 23 24(S) 25 26 27 badminton 28 29 30 31(S) 标题：Life record作者：末日没有进行曲链接：link时间：1565222122000声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/08/Life-record/"},{"title":"Log4j 2 踩坑","text":"现在 Log2j 4 基本是 Java 中使用最广泛的日志框架了，记录一些遇到的坑。 如果我们在 log4j2.xml 中使用如下配置，会报错。123456789 &lt;Appenders&gt; &lt;Appender type=\"Console\" name=\"STDOUT\"&gt; &lt;Layout type=\"PatternLayout\" pattern=\"%m MDC%X%n\"/&gt; &lt;Filters&gt; &lt;Filter type=\"MarkerFilter\" marker=\"FLOW\" onMatch=\"DENY\" onMismatch=\"NEUTRAL\"/&gt; &lt;Filter type=\"MarkerFilter\" marker=\"EXCEPTION\" onMatch=\"DENY\" onMismatch=\"ACCEPT\"/&gt; &lt;/Filters&gt; &lt;/Appender&gt;&lt;/Appenders&gt; 报错： 2019-08-23 10:04:25,750 RMI TCP Connection(3)-127.0.0.1 ERROR Error processing element Appender ([Appenders: null]): CLASS_NOT_FOUND 这是因为在 Log4j 2 中，指定 appender 的类型被元素的名称取代了，不能再使用一个 type 属性了。我们需要将配置换成下面这种形式。 123456789&lt;Appenders&gt; &lt;Console name=\"STDOUT\"&gt; &lt;Layout type=\"PatternLayout\" pattern=\"%m MDC%X%n\"/&gt; &lt;Filters&gt; &lt;Filter type=\"MarkerFilter\" marker=\"FLOW\" onMatch=\"DENY\" onMismatch=\"NEUTRAL\"/&gt; &lt;Filter type=\"MarkerFilter\" marker=\"EXCEPTION\" onMatch=\"DENY\" onMismatch=\"ACCEPT\"/&gt; &lt;/Filters&gt; &lt;/Console &gt;&lt;/Appenders&gt; 注意：Filter 标签也是不允许的，参考下面。 同理，我们还可能会遇到如下报错： 1232019-08-23 10:54:48,747 RMI TCP Connection(4)-127.0.0.1 ERROR Console contains an invalid element or attribute &quot;Layout&quot;2019-08-23 10:54:48,747 RMI TCP Connection(4)-127.0.0.1 ERROR Filters contains an invalid element or attribute &quot;Filter&quot; 也是因为我们使用了不正当的标签 Layout, Filter，log4j2 已经不使用这些标签了，我们需要直接将其替换为 type 对应的标签，而不是使用 type 来指定具体的 Layout 和 Filter。 如果我们的 PatternLayout 设置为 %m%n，则在打印异常日志时每行的末尾会将 jar 的信息打出来，比如：12345...at java.net.InetAddress.getAllByName(InetAddress.java:1127) ~[?:1.8.0_201] at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) ~[httpclient-4.5.2.jar:4.5.2] at org.apache.http.impl.conn.DefaultClientConnectionOperator.resolveHostname(DefaultClientConnectionOperator.java:262) ~[httpclient-4.5.2.jar:4.5.2]... 这是因为我们没有显示指定 exception 的 Converter。log4j 会给我们提供一个默认的 %xEx ，这个 pattern 包含 jar 包的信息等。如果我们不想让其出现，可以指定我们的 PatternLayout 为 %m%ex%n。其中，%m 表示 %message, %n 表示输出换行符。 标题：Log4j 2 踩坑作者：末日没有进行曲链接：link时间：2019-08-26声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/26/Log4j-2-踩坑/"},{"title":"Tomcat 监控自动重启脚本","text":"记录一个 Tomcat 监控自动重启脚本 123456789101112131415161718192021222324252627#!/bin/sh# monitor_tomcat.sh# crontab # */5 * * * * bash /home/tryking/crontab/monitor_tomcat.sh &gt;&gt; /home/tryking/crontab/crontab.log 2&gt;&amp;1# Please put tryking to /etc/cron.allow (allow user tryking enable crontab)tomcat_pid=$(ps aux | grep catalina.home | grep -v grep | awk '{print $2}')tomcat_start_script_file=/home/tryking/crontab/tomcat_start_script_filemonicot_log_file=/home/tryking/crontab/monitor.logecho $tomcat_pidMonitor() { echo \"[info] start monitor Tomcat...[$(date +'%F %H:%M:%S')]\" if [[ $tomcat_pid ]]; then echo \"[info] tomcat is running, record the start script to $tomcat_start_script_file\" ps aux | grep catalina.home | grep -v grep | awk '{for(i=1;i&lt;=NF;i++)print $i}' | grep catalina.home | awk -F '=' '{print $2}' | uniq | sed 's/$/\\/bin\\/startup.sh/g' | sed 's/^/bash /g' &gt; $tomcat_start_script_file else echo \"[info] tomcat is not running, start tomcat by $tomcat_start_script_file]\" cat $tomcat_start_script_file | while read line do #statements echo $line eval $line done fi}Monitor &gt;&gt; $monicot_log_file 标题：Title作者：末日没有进行曲链接：link时间：2019-03-20声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/03/20/Tomcat-监控自动重启脚本/"},{"title":"ArrayList-Part1","text":"构造方法ArrayList共有三个构造方法 无参构造方法 public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;} transient Object[] elementData;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; 无参构造方法会创建一个Object数组，其实这里并没有指定数组的大小。但是不知道为什么JDK文档中说是指定一个Capacity为10的list。 指定初始Capacity的构造方法 public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot; + initialCapacity); }} 此构造方法会创建一个Capacity为指定数值的ArrayList。 以一个集合创建ArrayList的构造方法 public ArrayList(Collection&lt;? extends E&gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // defend against c.toArray (incorrectly) not returning Object[] // (see e.g. https://bugs.openjdk.java.net/browse/JDK-6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; }} 此构造方法会将传进来的集合c的数据复制给本身的数据数组。然后对数据数组的长度做了判断，如果长度不等于0的话将其类的类型做了判断，文档中说是这里为了修复一个bug，暂不做深究。当长度等于0时，将数据数组置为了空数组 EMPTY_ELEMENTDATA 。 元素变更add 一个参数 public boolean add(E e) { modCount++; add(e, elementData, size); return true;} 这就是我们平时使用最多的方法add，此方法先将modCount参数做了++处理，然后调用了私有方法add，私有方法如下： private void add(E e, Object[] elementData, int s) { if (s == elementData.length) elementData = grow(); elementData[s] = e; size = s + 1; }此方法对 this.elementData 的长度和 this.size 做了判断，即如果已存在的list大小和数组长度相同的话，要想继续添加元素，则需要对数组进行扩容（grow()方法）。然后将数组的s位置置为e，并将list的size加了1。 两个参数（指定位置） public void add(int index, E element) { rangeCheckForAdd(index); modCount++; final int s; Object[] elementData; if ((s = size) == (elementData = this.elementData).length) elementData = grow(); System.arraycopy(elementData, index, elementData, index + 1, s - index); elementData[index] = element; size = s + 1;} 此方法首先对index的值做了判定，不符合时直接抛出异常。然后modCount做了++操作。接着又对list的大小和数组的长度做了判断，当两者相等时，对list进行扩容（grow()）。最关键的赋值一步使用了jdk的native方法System.arraycopy()，留下了index位置并将其置为传进来的值，最后再对size的值进行+1操作。 添加一个集合 public boolean addAll(Collection&lt;? extends E&gt; c) { Object[] a = c.toArray(); modCount++; int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); System.arraycopy(a, 0, elementData, s, numNew); size = s + numNew; return true;} 此方法首先将集合c的元素取出来作为了一个数组a，这里使用了toArray方法，最终其实使用的是native方法 System.arraycopy 方法。如果数组a的大小为0，直接返回false。如果现有的Capacity不能容纳新添加的集合元素，则对其进行扩容（grow()，这里增加了一个参数最小capacity）。接着使用System.arraycopy对数组进行拷贝赋值，并置size为新值。 在指定位置添加一个集合 public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); Object[] a = c.toArray(); modCount++; int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); int numMoved = s - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size = s + numNew; return true;} 首先还是判断了index的合法性。然后将集合的元素放到数组a中，如果数组a的大小为0，直接返回false。如果capacity剩余容量不足以容纳a，则进行扩容处理。判断添加的位置：如果添加的位置不在原有的size位，则需要将原有数组的index位置以后的值放置到后面几位，空出新添加的值的位置。再讲新添加的值填充到对应的位置上。最后将size的值置为新值。 元素变更remove 移除元素 public boolean remove(Object o) { final Object[] es = elementData; final int size = this.size; int i = 0; found: { if (o == null) { for (; i &lt; size; i++) if (es[i] == null) break found; } else { for (; i &lt; size; i++) if (o.equals(es[i])) break found; } return false; } fastRemove(es, i); return true;} 此方法首先对元素o的值进行了判断，然后在数组中找是否有此值，因为用了双层的嵌套，所以这里使用了outer方法来跳出循环。如果没有找到此元素，直接返回false，如果找到了此元素，利用找到的位置进行fastRemove操作。 private void fastRemove(Object[] es, int i) { modCount++; final int newSize; if ((newSize = size - 1) &gt; i) System.arraycopy(es, i + 1, es, i, newSize - i); es[size = newSize] = null; }在fastRemove中，先对modCount做了++操作，接着判断要移除的位置是否在前size-1位上，如果在，则使用native方法进行System.arraycopy，不在则忽略。最后对size重新赋值为size-1，并将数组的size位置为null。 移除指定位置的元素 public E remove(int index) { Objects.checkIndex(index, size); final Object[] es = elementData; @SuppressWarnings(&quot;unchecked&quot;) E oldValue = (E) es[index]; fastRemove(es, index); return oldValue;} 此方法首先检查了index为合法的值（这里调用了Objects的方法，里面的实现很简单，就是对index和0与size的大小做了判断，应该是要统一判断抛出异常的）。然后和上面的方法一样，使用fastRemove方法进行了移除操作。","link":"/2018/06/13/arraylist/"},{"title":"余生互相关照","text":"晚安","link":"/2018/05/12/e4-bd-99-e7-94-9f-e4-ba-92-e7-9b-b8-e5-85-b3-e7-85-a7/"},{"title":"使用XPath定位HTML元素","text":"XPath是非常简洁，非常优雅的一种确定HTML元素的方式。 基本介绍对于XPath的定位，主要有两种方式： 如果一个条件后面附加的是 【 / 】， 则表示下一步要匹配的节点在下一层。如果一个条件后面附加的是 【 [] 】，则表示下一步要匹配的节点在本层，但是会过滤掉一些不满足条件的节点。比如： /foo/bar 从root节点开始 /foo ：对于任意一个节点（目前是仅是root节点，/ 表示从root节点开始，//表示从任意位置节点开始），获取它的子节点（在这里，root节点总是确定的），检查哪些子节点是 foo 元素，并把这些子节点作为一个新的集合。 /bar ：对于第2步中新的集合中的每一个节点，获取它的子节点，检查这些子节点哪些是bar元素，并将它们放到新的集合中。此集合中的元素就是我们要获取的对象。 /foo[bar] 从root节点开始 /foo ：对于任意一个节点（目前仅是root节点，同上），获取它的子节点，检查这些子节点中哪些是foo元素，将这些子节点放到一个新的集合中。 [bar] ：对于第2步中新的集合中的每一个节点，获取它的子节点，检查这些子节点中是否有bar元素，如果没有，则将此节点舍弃（此节点代表第2步中集合中的节点）。此集合中的元素就是我们要获取的对象。 以上两种方式基本确定了XPath的使用规则，最后，还有一个用 axis 【 :: 】作为前缀分隔的方式，这种axis明确指定了在检查条件前是哪些节点集合应该被选择。 比如： /foo/following-sibling::bar 以root节点开始 /foo ：对于任意一个节点，获取它的子节点，检查哪些子节点是foo元素，把这些节点放入一个新的集合。 /following-sibling::bar ：对于第2步中集合中的任意一个节点，获取它所有的兄弟节点，检查哪些是bar元素，然后将它们放入新的集合。此集合中的元素就是我们要获取的对象。 特别地，对于当前节点的子节点是没有必要声明的，即 child:: 这种是默认的方式（不必要写，写了当然也没错）。因此，我们上面提到的 /foo/bar 和 /foo[bar] 实际上分别代表： /child::foo/child::bar 和 /child::foo[child::bar]通过比较这些表达式以及它们所代表的含义，我们说xpath是非常简洁非常美丽的一种表达HTML元素的方式一点儿也不为过。 当然，还有一些其他的句法可以和 child:: 一样可以省略，比如，你可以使用@foo 代替 attribute::foo， /descendant-or-self::foo 可以写成 //foo。 句法规则及示例 介绍xpath的详细规则以及示例 条件 [] 选择元素 AAA 的 第一个 BBB 子元素/AAA/BBB[1] 选择元素 AAA 的最后一个 BBB 子元素/AAA/BBB[last()] 属性 选择所有的属性 @id//@id 选择所有拥有 name 属性的 BBB 元素//BBB[@name] 选择有任意属性的 BBB 元素//BBB[@*] 选择没有任何一个属性的BBB元素//BBB[not(@*)] 属性值 选择有属性 id=b1 的BBB元素//BBB[@id=’b1’] 节点数量 选择有两个子节点BBB 的元素//*[count(BBB)=2] 选择有两个子元素的元素//[count()=2] name等函数的使用 name()函数：返回元素的名称。 starts-with函数：如果第一个参数的string值以第二个参数string值开始，返回true。 contains函数：如果第一个参数的string值包含第二个参数的string值，返回true。 例如： # 等价于 //BBB //*[name()=&apos;BBB&apos;] # 选择所有以字母B开头的元素 //*[starts-with(name(), &apos;B&apos;)] # 选择所有名称包含字母C的元素 //*[contains(name(), &apos;C&apos;)] string-length函数 string-length方法：返回string的字符个数 你应该使用 &lt; 代替 &lt; ，使用 &gt; 代替 &gt; # 选择名字小于三个字符的元素 //*[string-length(name()) &lt; 3] 使用 | 组合XPaths 选择所有的CCC元素和BBB元素//CCC | //BBB 使用 axis Child axis，以下等价于/AAA/child::AAA Descendant axis选择 /AAA/BBB 的所有的子孙元素/AAA/BBB/descendant::* 选择有CCC祖先的所有的DDD元素//CCC/descendant::DDD Parent axis选择所有的DDD元素的父元素//DDD/parent::* Ancestor axis选择给定绝对路径元素的所有的祖先元素/AAA/BBB/DDD/CCC/ancestor::* 参考及更多用法XPath 1.0 Tutorial","link":"/2018/05/20/e4-bd-bf-e7-94-a8xpath-e5-ae-9a-e4-bd-8dhtml-e5-85-83-e7-b4-a0/"},{"title":"编写一个MongoDB数据库备份脚本","text":"公司的开发环境多人共用一个MongoDB数据库，为了防止自己的数据被别人误删，可以写一个每天备份数据的定时任务来备份数据。 #!/bin/sh DB_HOST=&quot;10.10.10.1:10001&quot; DB_NAME=&quot;music&quot; USER=&quot;music&quot; PWD=&quot;haha@2018&quot; SINGER_RECORD=&quot;pro_search_singer_record&quot; OUT_DIR=&quot;/home/dkt/crond/back_up_data_temp&quot; #临时备份目录 TAR_DIR=&quot;/home/dkt/crond/back_up_data&quot; #备份存放路径 DATE=$(date +%Y_%m_%d) #获取当前系统时间 echo &quot;-----当前时间为$DATE-----&quot; DAYS=7 #DAYS=7代表删除7天前的备份，即只保留最近7天的备份 TAR_BAK=&quot;mongod_bak_$DATE.tar.gz&quot; #最终保存的数据库备份文件名 cd $OUT_DIR echo &quot;-----删除原有备份文件-----&quot; find $OUT_DIR/ -print rm -rf $OUT_DIR/* mkdir -p $OUT_DIR/$DATE echo &quot;-----开始备份数据-----&quot; #mongoexport可以使用绝对路径，以防止命令找不到 mongoexport -h $DB_HOST -d $DB_NAME -u $USER -p $PWD -c $SINGER_RECORD -o $OUT_DIR/${DATE}/singer_record # -h: MongoDB所在服务器地址 # -d: 需要恢复的数据库实例 # -c: 需要恢复的集合 # -f: 需要导出的字段(省略为所有字段) # -o: 表示导出的文件名 mongodump -h $DB_HOST -o $OUT_DIR/$DATE #备份全部数据库，具体可以参照： mongodump --help echo &quot;-----开始压缩备份文件-----&quot; tar -zcvf $TAR_DIR/$TAR_BAK $OUT_DIR/$DATE #压缩为.tar.gz格式 echo &quot;-----删除7天前的备份文件-----&quot; find $TAR_DIR/ -mtime +$DAYS -delete #删除7天前的备份文件问题 将脚本添加到定时任务crondtab中，可能会找不到 mongodump 命令，需要使用 mongodump 的全路径。 当密码中有特殊字符 @ 等时，会报 [error connecting to db server: server returned error on SASL authentication step: Authentication failed.] 此错误。这时需要使用 -p '密@码' 来代替，具体用变量名如何来代替还未找到解决方法。","link":"/2018/06/05/e7-bc-96-e5-86-99-e4-b8-80-e4-b8-aamongodb-e6-95-b0-e6-8d-ae-e5-ba-93-e5-a4-87-e4-bb-bd-e8-84-9a-e6-9c-ac/"},{"title":"自然语言处理博客收集","text":"苏剑林 刘建平 用gensim学习word2vec 中文文本挖掘预处理流程总结","link":"/2018/05/13/e8-87-aa-e7-84-b6-e8-af-ad-e8-a8-80-e5-a4-84-e7-90-86-e4-bc-98-e7-a7-80-e5-8d-9a-e5-ae-a2/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/05/30/hello-world/"},{"title":"Java中的自动装箱，自动拆箱","text":"包装类的由来虽然我们常说在Java中我们不缺对象，任何时刻都可以 new 一个对象，一切皆为对象。但是在Java中还存在一些原始数据类型，比如 int，long，float，double，byte，short，boolean，char。这些原始数据类型并不是对象。 在Java中，引入了对于8中基本数据类型的包装类，比如对于 int 的包装类 Integer 。在Integer中，有一个int字段用于存储数据值，并且还提供了一些基本数据类型int做不到的事情，比如和字符串的转换等。 装箱拆箱当我们想要创建一个 Integer 对象时，传统的做法是 Integer x = Integer.valueOf(&quot;3&quot;);但是有了自动装箱后，我们只需要用 Integer x = 3;当编译时，Javac会自动帮我们装箱，把 Integer x = 3; 转换为 Integer x = Integer.valueOf(&quot;3&quot;); ，这极大的方便了我们代码的书写。 相应地，拆箱的操作会将 int y = x 转换为 int y = x.intValue();","link":"/2018/06/06/java-e4-b8-ad-e7-9a-84-e8-87-aa-e5-8a-a8-e8-a3-85-e7-ae-b1-ef-bc-8c-e8-87-aa-e5-8a-a8-e6-8b-86-e7-ae-b1/"},{"title":"Linux下编写一个Python自动重启脚本","text":"团队中有一大部分的监控任务都是自己来做的，这其中包括了很多脚本，主要是Python脚本。但是有时由于不可预料的原因，Python会异常终止，因此编写一个自动检测Python脚本是否异常终止的脚本，当异常终止时，重新启动即可。 #!/bin/sh # 一定要保证路径下Python文件唯一 base_path=&apos;/home/report724&apos; pythons_3=(&quot;ElkMaster.py&quot; &quot;CopyAndCrawlerDayData.py&quot; &quot;RabbitMQStatus.py&quot;) pythons_2=(&quot;CoreMonitor.py&quot; &quot;SparkMonitor.py&quot; &quot;AthenaErrorLog.py&quot; &quot;ServiceIpCount.py&quot; &quot;AthenaForOperations.py&quot;) function start_python_3(){ # $1 为程序的名字，即 *.py program=$1 echo $program pro_path=$(find $base_path -name $program) echo $pro_path cd ${pro_path%/*} nohup ppython3 $pro_path &gt; /dev/null &amp; curl &quot;http://172.30.111.111:8088/report/monitor/sendSmsCode?phoneNumber=15788888888&amp;captcha=999999&amp;message=${program}已重启&quot; } function start_python_2(){ # $1 为程序的名字，即 *.py program=$1 echo $program pro_path=$(find $base_path -name $program) echo $pro_path cd ${pro_path%/*} nohup python $pro_path &gt; /dev/null &amp; curl &quot;http://172.30.111.111:8088/report/monitor/sendSmsCode?phoneNumber=15788888888&amp;captcha=999999&amp;message=${program}已重启&quot; } # index=0 echo `date &quot;+%Y-%m-%d %H:%M:%S&quot;` for python in ${pythons_3[@]}; do #statements ps aux | grep $python | grep -v grep if [[ $? -ne 0 ]]; then #statements echo &quot;start process.....&quot; start_python_3 $python else echo &quot;running.....&quot; fi # echo $index # index=`expr $index + 1` done for python in ${pythons_2[@]}; do #statements ps aux | grep $python | grep -v grep if [[ $? -ne 0 ]]; then #statements echo &quot;start process.....&quot; start_python_2 $python else echo &quot;running.....&quot; fi # echo $index # index=`expr $index + 1` done因为有很多脚本，有些是用Python2运行的，有些是用Python3运行的，因此对Python2和Python3（我设置的本机Pythone3命令为ppython3）分别写了函数。 函数中还用一个curl访问了一个短信通知接口，当程序重启后会进行短信通知。 把此脚本添加到 crontab 任务中，每5分钟运行检测一次即可。 待完善 对程序是否启动成功没有加以判断，默认是启动成功的。 必须保证在 base_path 路径下要监控的Python脚本文件是唯一的，否则无法正确找出其所在路径。 注意此脚本需要用命令source 脚本.sh 来执行，否则 cd ${pro_path%/*} 不会执行成功。","link":"/2018/05/26/linux-e4-b8-8b-e7-bc-96-e5-86-99-e4-b8-80-e4-b8-aapython-e8-87-aa-e5-8a-a8-e9-87-8d-e5-90-af-e8-84-9a-e6-9c-ac/"},{"title":"Mac版的Charles乱码怎么办？","text":"之前在Windows上用的抓包工具主要是Fiddler，由于之前对Fiddler用的也不是很熟，在Windows上也是各种不顺，遂查了下Mac下哪个软件不错，网上一致推荐Charles，那就下个Charles来一发吧。 装好之后，立马就来一发，让人崩溃的是 - 这是啥？怎么全是乱码？！网上找了一些解决办法，经过多次尝试，找到一个靠谱的，记录如下。 安装SSL证书 如上图，点击按照证书，如果运气不好，会出现如下情形： 这时，可以选择保存CA文件到本地，然后自己在拖到‘系统钥匙串’中。此步需要输入密码。 放进去后，会发现有爆红。 证书不受信任，那我们就自己设置一下吧。双击刚拖入的证书，进入设置，设置如下所示，把对应位置设置为‘始终信任’，然后关闭即可。此步需要输入密码。 完成后可以看到已经不爆红了。 设置 Charles 的 SSL选项安装完证书后，还需要设置Charles的SSL选项，点击Proxy → SSL Proxying Settings，进入设置页面。在设置页面点击Add，设置如下： 然后OK保存，此时重新刷新网页，可以看到我们的Charles已经正常工作了。 后记Chrome浏览器默认走的不是系统本身的代理，而Charles代理的是系统本身。因此Chrome使用时需要配置代理或者直接使用SwitchyOmega等软件监听本地的8888端口（Charles默认为8888端口）。","link":"/2018/05/25/mac-e7-89-88-e7-9a-84charles-e4-b9-b1-e7-a0-81-e6-80-8e-e4-b9-88-e5-8a-9e-ef-bc-9f/"},{"title":"Python中的可迭代对象和生成器","text":"可迭代对象当我们创建一个列表后，我们可以遍历这个列表来进行读取其中的元素，列表便是一个可迭代对象： test_list = [1, 2, 3, 4] for test_item in test_list: print(test_item) 1 2 3 4当我们使用列表生成式来建立列表时，也可以建立一个可迭代对象： test_list = [x*2 for x in range(4)] for test_item in test_list: print(test_item) 0 2 4 6对于我们可以使用 for .. in ..语法的对象便叫做一个迭代器。像列表，字符串等等，由于它们的内容都是存储在内存中的，因此我们可以通过 for .. in .. 方式来进行多次读取。但是如果我们有大量数据呢？ 生成器生成器也是可以迭代的，但是它只可以被读取一次。因为它的值并不是在内存中，而是实时地生成数据： test_generator = (x*2 for x in range(4)) for test_item in test_generator: print(test_item) 0 1 4 6这种形式便叫做生成器。我们生成的test_generator只能被遍历（其实不是遍历）一次。当我们使用 for ... in .. 时，生成器会先计算0，然后1，接着4，6…并没有在我们遍历前就把元素生成放在内存中。当我们的数据量比较大时，这样便可以节省内存。 yieldyield 类似于 return ，只不过它返回的是个生成器。 def create_generator(): test_list = range(4) for test_item in test_list: yield test_item*2 test_generator = create_generator() print(test_generator) &lt;generator object create_generator at 0x10d6ebfc0&gt; for i in test_generator: print(i) 0 1 4 6当我们输出test_generator时，可以发现并不像输出列表一样将它的元素都打印出来，而是返回来一个对象的地址值，这里的test_generator是一个Object对象。只有当我们遍历的时候，它才会将元素逐个计算出来。 当我们调用yield函数时，yield后面的代码并不会立马执行，它只会返回一个生成器对象。当我们使用 for ... in ...时，才会开始逐步执行。","link":"/2018/05/27/python-e4-b8-ad-e7-9a-84-e5-8f-af-e8-bf-ad-e4-bb-a3-e5-af-b9-e8-b1-a1-e5-92-8c-e7-94-9f-e6-88-90-e5-99-a8/"},{"title":"shell列表操作&检查服务器接口是否可用","text":"在写shell脚本时，列表是很常见的一种操作，这里以一个检查服务器接口是否可用的脚本来熟悉下列表的操作。 #!/bin/sh ips=(&quot;172.30.111.100:7001&quot; &quot;172.30.111.101:7001&quot;) urls=(&quot;/test/test1&quot; &quot;/test/test2&quot;) for ip in ${ips[@]}; do for url in ${urls[@]}; do #statements #echo $url echo &quot;$ip&quot;&quot;$url&quot; curl -X post &quot;$ip&quot;&quot;$url&quot; -I | grep --color 200 done done echo &quot;**over**&quot;shell中的列表的每个条目中间以空格分隔，遍历时使用 ${ips[@]} 来进行遍历。","link":"/2018/06/04/shell-e5-88-97-e8-a1-a8-e6-93-8d-e4-bd-9c-e6-a3-80-e6-9f-a5-e6-9c-8d-e5-8a-a1-e5-99-a8-e6-8e-a5-e5-8f-a3-e6-98-af-e5-90-a6-e5-8f-af-e7-94-a8/"},{"title":"test","text":"test","link":"/2018/06/13/test/"},{"title":"如何启动Jupyter","text":"Jupyter可以用来调试程序，因为它自带了tab键可以预览函数功能，因此对有一些比较生疏的函数的使用非常有利。 生成配置文件 jupyter notebook –generate-config 此命令会默认在 ~/.jupyter/文件夹下创建一个 jupyter_notebook_config.py 配置文件 生成密码 from notebook.auth import passwdpasswd() 进入Python命令行，导入passwd 模块，然后输入函数 passws() ，系统会让你确认两次密码来生成密码的加密值。此密码用于后面登录Jupyter。请将生成的密码加密值复制出来。 修改配置文件 在第1步我们生成了默认的配置文件，这里需要对其做修改。打开 jupyter_notebook_config.py 文件，对下列值进行修改。 c.NotebookApp.ip = &apos;&apos; c.NotebookApp.open_browser = False c.NotebookApp.port = 8899 c.NotebookApp.password = &apos;sha1:dcf8c8c7907b:e478faebf003200468cd738010c09db2c9bf3bcd&apos;其中，ip为本服务器ip，open_browser设置为 False 的话启动Jupyter不会默认打开浏览器，port为想要启动Jupyter的端口号，passwd 就是你在第2步生成的密码加密字符串了。修改完成后保存即可。 启动Jupyter jupyter notebook 输入命令即可启动Jupyter，这时访问你的ip+端口号即可进行访问。如果需要后台运行，可以使用 nohup jupyter notebook &amp; 命令。","link":"/2018/05/23/trashed/"},{"title":"为啥我的 Gradle 一直 build 不成功？","text":"为啥我的 Gradle 一直 build 不成功呢？这都得从当年折腾的翻墙说起。 最近在自己电脑上 Build 项目一直编译不过去，刚开始以为是 Maven 仓库配置的不对，特意去阿里云的代理库网站比对了自己的配置，发现是没有问题的。但是就是 Build 过不去，查看日志只是说是找不到相应的 library，很是郁闷。 静下心来仔细又去排查报错日志的时候，发现了这样一条日志。 1Connect to 127.0.0.1:1087 [/127.0.0.1] failed: Connection refused (Connection refused)&lt;eol&gt;Caused by: java.net.ConnectException: Connection refused (Connection refused)&lt;/i&gt; What? 1087 端口连不上，我 build 项目，你连接 1087 端口干撒？待我苦苦冥想后，想起来自己之前使用 Shadowsocks 貌似使用的是这个端口，后来因为 Shadowsocks 不好用，就购买了第三方的服务。这个可能是当时自己因为网络不好用，配置了代理，后来换了代理后就忘记修改了，代理在哪里配置的呢？当然是 Gradle 的全局配置文件里，于是，打开 ~/.gradle/gradle.properties 文件，发现了罪魁祸首。 1234systemProp.https.proxyPort=1087systemProp.http.proxyHost=127.0.0.1systemProp.https.proxyHost=127.0.0.1systemProp.http.proxyPort=1087 把这几行配置注释掉，重新 build 项目。嗯，阿里云代理库的速度还是可以的。 标题：为啥我的 Gradle 一直 build 不成功？作者：末日没有进行曲链接：link时间：2020-05-30声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/05/30/为啥我的-Gradle-一直-build-不成功？/"},{"title":"优秀 blog 收集","text":"icarus 使用博客更换ICARUS主题","link":"/2019/07/05/优秀-blog-收集/"},{"title":"xargs 知多少？","text":"有了 xargs 神器，再也不用担心 Linux 上的数据操作了。 由来假如我们想查找当前服务器上运行的 Python 应用，并且列出它们的进程 id，我们可以使用 awk 命令进行操作。 1ps aux | grep python | awk -F &quot; &quot; &apos;{print $2}&apos; 查出来后，假如我们又想要把这些进程给强制删除呢？我想到了直接用 kill -9 进程ID，我们来试一下。 在这里，我命令后面直接跟了 kill -9，进程 ID 我以为管道符能直接给我传过来，但是并没有，这是咋回事？ 其实，在 Linux 命令中，大多数命令都不接受标准输入作为参数，只能在命令后直接跟上参数，这就导致我们无法使用管道符进行参数的传递。同样的命令还有 echo 等。 这时，我们的 xargs 就可以派上用场了，xargs 的作用就是将标准输入转为命令行参数。对于上面的场景，我们可以这样做 ps aux | grep python | grep -v grep | awk -F &quot; &quot; '{print $2}'| xargs kill -9 执行命令后，什么都没输出。我们继续执行查询命令查找 Python 进程，可以看到，进程已经都被杀掉了。 详细介绍xargs 命令的格式为 xargs [-option] [command]，最终真正执行的命令是 command，它接受来自 xargs 的传递的参数。command 可以缺省，默认为 echo。 进阶使用-p 参数 / -t 参数有时候我们的 command 命令比较复杂时我们可能想要知道最终到底执行什么操作，这时我们可以加上 -p 参数，加上后会打印出最终执行的命令，让我们来确认是否执行。 如果使用 -t 参数的话会直接打印命令并执行，不会询问我们。 -I 参数如果我们的命令需要多次使用命令行参数时，我们可以使用 -I 参数，-I 后面跟的是命令行参数的替代字符串。比如 在命令中，我们使用 -I {} 指定了 {} 作为我们的命令行参数，紧接着使用了 -n 1，它表示我们指定将每一项执行一次命令。最后我们执行 sh 命令输出了命令行参数，并创建了对应的文件。 以上就是一些常用的参数，如果还想了解更多，可以使用 man xargs，毕竟，自己动手，丰衣足食。 -_- 标题：xargs 知多少？作者：末日没有进行曲链接：xargs 知多少？时间：2020-03-20声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/03/20/xargs知多少？/"},{"title":"使用 @ConfigurationProperties 在 Spring Boot 中加载配置","text":"使用 Spring Boot 加载配置文件的配置非常便利，我们只需要使用一些注解配置一下就能很方便地加载配置项了。今天我们谈一谈 ConfigurationProperties 注解的使用，ConfigurationProperties可以把配置文件中有相同前缀的配置在一个配置类中直接省去相同前缀进行读取，甚至还可以将相同前缀的配置自动封装成实体类。 步骤创建标准 Spring Boot 工程首先，我们使用一个标准的 Spring Boot 的依赖设置，在 build.gradle文件的plugins以及dependencies中加入相关内容，如下： 123456789plugins { id 'org.springframework.boot' version '2.1.6.RELEASE' id 'java'}dependencies { implementation 'org.springframework.boot:spring-boot-starter' testImplementation 'org.springframework.boot:spring-boot-starter-test'} 然后创建 Spring application 类，用于启动我们的 Spring Boot 应用。（如果使用 IDEA 进行开发，使用 New Project -&gt; Spring Initializa 创建 Spring Boot 应用非常方便，IDEA 会帮我们自动生成 Spring application 类。）我们顺便在Spring Application 类中加上一个 component，方便我们进行测试。(实现了CommandLineRunner的 component 会在应用启动成功后运行) 1234567891011121314151617@SpringBootApplicationpublic class ConfigurationApplication { public static void main(String[] args) { SpringApplication.run(ConfigurationApplication.class, args); } @Component class StartupRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(\"Application running\"); } }} 编写配置文件Spring Boot 中默认的配置文件是 application.properties，但是我们通常会将自定义的配置单独放在一个文件中，这里我们在 resources 目录下创建一个配置文件 configprops.properties，并加入以下配置内容： 123user.name=Trykinguser.password=Securityuser.age=18 可以看到，三个配置都有相同的前缀 user。 编写配置读取类接下来我们编写一个配置读取的类文件 12345678910111213141516171819202122232425262728293031323334353637@Configuration@PropertySource(\"classpath:configprops.properties\")@ConfigurationProperties(prefix = \"user\")public class ConfigProperties { private String name; private String password; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { ... }} Configuration 注解表明我们需要一个配置 Bean，Spring 启动的时候会在应用 Context 中帮我们创建一个 Java Bean。这里使用 Component 也是可以的，但是为了代码的可读性，我们使用 Configuration 更合理。 PropertySource 注解用来定义我们的配置文件位置，如果没有此注解的话，Spring Boot 默认找的是 application.properties 文件。 ConfigurationProperties 注解便是我们的主角了，它用来定义我们要加载的配置的前缀，我们这里定义的是 user，因此 Spring Boot 会去寻找 user 前缀的配置。 在此类中，我们定义了三个属性，分别是 name, password, age，和我们配置文件中的属性是一一对应的。因为 Spring 使用标准的 Java Bean Setters，因此我们需要实现各个属性的 getter &amp; setter 方法。 这样我们就完成了所有的配置，Spring 会自动将我们在配置文件中含有 user 前缀的配置绑定到 ConfigProperties 类中具有相同名字的属性上。 测试配置成功与否然后我们在 ConfigurationApplication 启动类中定义的 StartupRunner component 中增加对此配置文件的测试，我们使用此配置的 toString() 方法进行输出。 12345678910111213141516171819202122private final ConfigProperties configProperties;// 引入配置 bean@Autowiredpublic ConfigurationApplication(ConfigProperties configProperties) { this.configProperties = configProperties;}public static void main(String[] args) { SpringApplication.run(ConfigurationApplication.class, args);}@Componentclass StartupRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(\"Application running\"); // 输出 System.out.println(configProperties.toString()); }} 最后，我们启动 Application，可以看到命令行中成功输出了我们的配置信息。 12Application runningConfigProperties{name=&apos;Tryking&apos;, password=&apos;Security&apos;, age=18} 进阶：加载嵌套属性我们还可以使用 ConfigurationProperties 来实现复杂对象的属性加载，比如 Map，List，以及实体类。 我们在配置文件中继续增加更多的配置： 12345678910111213141516# Simple propertiesuser.name=Trykinguser.password=Securityuser.age=18# List propertiesuser.friends[0]=Tomuser.friends[1]=Jack# Map propertiesuser.scores.java=90user.scores.python=95# Object propertiesuser.job.address=Beijinguser.job.salary=50000 然后在配置读取类中增加对这些属性的读取。 12345678private String name;private String password;private int age;private List&lt;String&gt; friends;private Map&lt;String, Integer&gt; scores;private Job job;...set... 同时不要忘记 getter &amp; setter 方法的实现，以及实体 Bean Job的定义（同样需要实现 getter &amp; setter 方法）。 完成后，我们重新运行 Application，可以看到这些复杂配置也成功读取出来了： 12Application runningConfigProperties{name='Tryking', password='Security', age=18, friends=[Tom, Jack], scores={java=90, python=95}, job=Job{address='Beijing', salary=50000}} 进阶：在 @Bean 上使用 @ConfigurationProperties我们还可以在具有 @Bean 注解的方法上使用 @ConfigurationProperties。 当我们想在我们引用的外部第三方 component 中绑定一些属性时，此方法特别有用。 我们先创建一个简单的 Item 供后面的类引用。 123456public class Item { private String name; private int size; // standard getters and setters} 接下来，我们在 @Bean 注解上使用 @ConfigurationProperties，以绑定我们配置的属性到此 Bean 上。 123456789@Configurationpublic class ConfigProperties { @Bean @ConfigurationProperties(prefix = \"item\") public Item item() { return new Item(); }} 这样，Spring Context 会将所有带有 item 前缀的属性帮我们映射到 Item 实例中。 配置验证@ConfigurationProperties 提供了属性验证的功能，使用 JSR-303 格式来进行验证。支持验证需要在类上增加@Validated注解，然后我们可以进行如下验证： hostName 不允许为空 12@NotBlankprivate String hostName; authMethod 属性的长度为 1 - 3 个字符 12@Length(max = 4, min = 1)private String authMethod; port 属性的取值从 1025 到 65536 123@Min(1025)@Max(65536)private int port; from 属性必须满足 Email 格式 12@Pattern(regexp = &quot;^[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,6}$&quot;)private String from; 通过这种方式我们就可以验证属性是否合规，而不用使用一系列的 if 、else 来进行验证了。 如果有验证无法通过，那么我们启动应用的时候 Application 将启动失败，并且抛出一个IllegalStateException异常。 相关代码Spring Boot Configuration","link":"/2019/06/30/使用-ConfigurationProperties-在-Spring-Boot-中加载配置/"},{"title":"使用 ELK 监控 Tomcat Access Log","text":"为什么要监控 Tomcat Access Log 呢？因为这里面保存了太多有用的信息了。 为什么要监控 Tomcat Access Log？Tomcat Access Log 的展示信息在 conf/server.xml 中进行配置，默认配置如下： server.xml123&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; 其中， 各个占位符的含义如下： 占位符 含义 %h 远程主机名 %l 远程逻辑 identd 用户名（总是返回 - ） %u 远程用户身份验证 %t 请求的日期和时间 %r 请求的第一行，包括请求的方式，URL 以及 HTTP协议 %s 响应的 HTTP 状态代码 %b 发送的字节数，不包括 HTTP 头 除了这些默认的展位符外，比较常用的还有 占位符 含义 %D 处理请求的时间（以毫秒为单位） 同时，我们在代码中写到 HTTP 头的信息同样也能在这里获取到，比如我们在 HTTP Header 中放入了一个 header-key，我们便可以在 server.xml 中使用 %{header-key} 进行获取，然后打印日志到 access log 中。 可以看到，Access Log 中存放了很多有用的信息，如果我们能将这些信息利用起来，无疑对我们的业务排查是非常高效的。比如我们可以统计我们的请求的处理时间，响应成功率，发送 response 的大小等等。 如何进行监控其实直接使用 ELK 便可以进行监控，使用 Logstash 把对应的日志处理，然后放到 ElasticSearch 中，最后再用 Kibana 进行展示。但是对于生产环境来说， Logstash 还是比较耗性能的。比较理想的做法是使用 Filebeat。 Filebeat 属于 Beats 家族，Beats 是单用途数据托运平台。它们以轻量级代理的形式存在于服务器上，并将来自成百上千台机器的数据发送到 Logstash 或 Elasticsearch。Filebeat 也可以对数据进行处理，然后直接存入 ES，但是考虑到对机器性能的影响，我更喜欢它将原始数据直接发送到 Logstash（和 Filebeat 不在相同机器），然后用 Logstash 将数据处理并放入 ES 中。 因此，监控的流程为 Filebeat 收集数据，将数据发送到 Logstash，然后 Logstash 对数据进行处理，并将处理后的数据发送到 ES，最后再用 Kibana 进行数据展示。 安装并配置 Filebeat下载并安装 Filebeatscript12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.2.1-x86_64.rpmsudo rpm -vi filebeat-7.2.1-x86_64.rpm 编辑配置文件修改 /etc/filebeat/filebeat.yml，设置 Tomcat Access Log 位置以及 Logstash 的连接信息（需要和下一步中安装的 ELK 中的信息保持一致）。 12345678910111213141516171819202122#=========================== Filebeat inputs =============================filebeat.inputs: # Each - is an input. Most options can be set at the input level, so# you can use different inputs for various configurations.# Below are the input specific configurations. - type: log # Change to true to enable this input configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. paths: # The Tomcat Access Log path - /usr/local/apache-tomcat-8.5.41/logs/localhost_access_log* ...#----------------------------- Logstash output --------------------------------output.logstash: # The Logstash hosts hosts: [&quot;localhost:5044&quot;] 启动 Filebeatscript12sudo filebeat setupsudo service filebeat start 安装 ELK推荐使用 docker，参照 docker-elk. 配置 Logstash修改 ${logstash}/pipeline/logstash.conf 设置 filebeat 的信息: (input.beats.port 需要和 filebeat 中的保持一致，此设置是用来供 filebeat 传输数据的监听接口, output.elasticsearch.hosts/user/password 需要正确设置，elk-docker 中默认为 eleatic/changeme) 123456789101112131415161718192021222324252627282930313233343536input { beats { port =&gt; 5044 type =&gt; &quot;logs&quot; }} filter { grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{IPORHOST:clientip}%{SPACE}%{USER:ident}%{SPACE}%{USER:auth}%{SPACE}\\[%{HTTPDATE:timestamp}\\]%{SPACE}\\&quot;(?:%{WORD:verb}%{SPACE}%{NOTSPACE:request}(?:%{SPACE}HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\\&quot;%{SPACE}%{NUMBER:response}%{SPACE}(?:%{NUMBER:bytes}|-)(?:%{SPACE}(?:%{NUMBER:duration}|-)%{SPACE}(?:-|%{NOTSPACE:header-key})%{SPACE}(?:-|%{NOTSPACE:header-signature})|)&quot; } } if &quot;_grokparsefailure&quot; not in [tags] { date { match =&gt; [ &quot;timestamp&quot; , &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ] } mutate { remove_field =&gt; [&quot;message&quot;] convert =&gt; [&quot;bytes&quot;, &quot;integer&quot;] convert =&gt; [&quot;duration&quot;, &quot;integer&quot;] } }} output { elasticsearch { hosts =&gt; &quot;elasticsearch:9200&quot; user =&gt; &quot;elastic&quot; password =&gt; &quot;changeme&quot; index =&gt; &quot;apache-access-log&quot; } stdout { codec =&gt; rubydebug }} 在匹配 tomcat access 日志中，我们修改了默认的 pattern，在此例中，我们的 tomcat access log pattern 为 123&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b %D %{header-key}i %{header-signature}i&quot; /&gt; 其中，header-key 和 header-signature 为我们在程序中加到 HTTP Header 中的属性，例如，以下为一条 log。 1127.0.0.1 - - [18/Aug/2019:18:22:40 -0700] &quot;POST /monitor/test HTTP/1.1&quot; 200 111 21 49c04731-3510-4020-b012-b24t64434ca4 412c473b-3550-4020-b012-b023064434ca4 配置 Kibana接下来，我们的工作就完成了，当日志发生变动时，Filebeat 会将日志传输给 Logstash，Logstash 会根据我们定义的 Pattern 将日志进行装换，然后存入 ElasticSearch，我们在 Kibana 中刷新拿到 ElasticSearch 中的 index 就可以配置我们想要的报表了。 标题：使用 ELK 监控 Tomcat Access Log作者：末日没有进行曲链接：使用 ELK 监控 Tomcat Access Log时间：2019-09-17声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/09/17/使用-ELK-监控-Tomcat-Access-Log/"},{"title":"使用 Json Schema 定义 API","text":"前面我们介绍了 Json Schema 的基本内容，这篇文章我们结合 jsonschema2pojo 工具深入分析如何使用 Json Schema 生成 API，学习更多关于 Json Schema 的关键字等知识。 jsonschema2pojo 该库提供了多种使用Json Schame文件生成 Java 类的方法，比如 Maven插件, Gradle插件, Ant任务, 以及直接使用命令行，甚至还可以在代码中直接使用，具体参照 jsonschema2pojo Getting Started 这里我直接采用 Mac 命令行的方式，在 Mac 下安装此命令的方式比较简单，直接运行 brew install jsonschema2pojo 安装即可。 properties在一个类中，最关键的就是属性了，每个类都可能有多个属性，在 Json Schema 中就是通过 properties 来定义类的属性的， properties 中的每个条目都是所定义类的一个属性。 比如，对于此 Json Schema MyObject.json： 12345678{ &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;foo&quot; : { &quot;type&quot; : &quot;string&quot; } }} 我们执行 jsonschema2pojo 任务后，可以生成对应的 Java 类： 123456789public class MyObject { private String foo; public String getFoo() { return foo; } public void setFoo(String foo) { this.foo = foo; }} type像我们 Java 中有多种类型，那不同的类型在 Json Schema 中如何表示呢？一般通用的转换如下所示，这也是 jsonschema2pojo 工具默认使用的转换方式： Schema Type Java Type string java.lang.String number java.lang.Double integer java.lang.Integer boolean java.lang.Boolean object 自己生成的类 array java.util.List array(with “uniqueItems”:true) java.util.Set null java.lang.object any java.lang.object 值的注意的是，如果我们增加了 usePrimitives 选项，对于 Integer, Double, Boolean 这三个包装类将会转换成基本类型 int, double, boolean。 additionalProperties我们平时开发中，为了类利于扩展，有时会给类增加一个Map类型的属性，这样当外部需要传更多的参数给我们时，不需要更改API，直接将参数放到这个 Map 里就可以快速实现。jsonschema2pojo同样也实现了这个功能，当我们没有指定additionalProperties属性为false或者没有指定additionalProperties属性时，jsonschema2pojo会为我们定义的类自动生成一个类型为Map的additionalProperties属性。 比如： 123{ &quot;type&quot; : &quot;object&quot;} 或者 1234{ &quot;type&quot; : &quot;object&quot;, &quot;additionalProperties&quot; : {}} 生成的类： 12345678910111213public class MyObject { private java.util.Map&lt;String, Object&gt; additionalProperties = new java.util.HashMap&lt;String, Object&gt;(); @org.codehaus.jackson.annotate.JsonAnyGetter public java.util.Map&lt;String, Object&gt; getAdditionalProperties() { return this.additionalProperties; } @org.codehaus.jackson.annotate.JsonAnySetter public void setAdditionalProperties(String name, Object value) { this.additionalProperties.put(name, value); }} itemsitems 用于指定我们定义 List 以及 Set 类型时的子元素详情，比如子元素的类型以及描述等。例如： 1234567891011{ &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;myArrayProperty&quot; : { &quot;type&quot; : &quot;array&quot;, &quot;items&quot; : { &quot;type&quot; : &quot;string&quot; } } }} 生成的属性： 1List&lt;String&gt; myArrayProperty; required如果一个属性在required中指定了，那么这个属性会有一个 Required 的注解，表明该属性是必需的。 uniqueItems这个就是我们上面表格中的用于区分 List 和 Set 的关键字了，如果我们定义的array中声明uniqueItems为true，那么最终转换为的属性的类型就为Set。 enum对于枚举类型的定义需要使用到此关键字，比如： 123456789{ &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;myEnum&quot; : { &quot;type&quot; : &quot;string&quot;, &quot;enum&quot; : [&quot;one&quot;, &quot;secondOne&quot;, &quot;3rd one&quot;] } }} 生成的枚举类： 12345678910111213141516171819202122232425262728@Generated(&quot;com.googlecode.jsonschema2pojo&quot;) public static enum MyEnum { ONE(&quot;one&quot;), SECOND_ONE(&quot;secondOne&quot;), _3_RD_ONE(&quot;3rd one&quot;); private final String value; private MyEnum(String value) { this.value = value; } @JsonValue @Override public String toString() { return this.value; } @JsonCreator public static MyObject.MyEnum fromValue(String value) { for (MyObject.MyEnum c: MyObject.MyEnum.values()) { if (c.value.equals(value)) { return c; } } throw new IllegalArgumentException(value); }} default如果我们需要某个属性有默认值，可以加上此参数，生成类的属性会自动实例化。具体可参照下表： Json Schema Java myString : { “type”:”string”, “default”:”abc”} myString : { “type”:”string”, “default”:”abc”}; myInteger : { “type”:”integer”, “default”:”100”} private Integer myInteger = 100; myNumber : { “type”:”number”, “default”:”10.3”} private Double myNumber = 10.3D; myMillis : { “type”:”string”, “format”:”utc-millisec”, “default”:”500”} private Long myMillis = 500L; myDate : { “type”:”string”, “format”:”date-time”, “default”:”500”} private Date myDate = new Date(500L); myDate : { “type”:”string”, “format”:”date-time”, “default”:”2011-02-24T09:25:23.112+0000”} private Date myDate = new Date(1298539523112L); myList : { “type”:”array”, “default”:[“a”,”b”,”c”]} private List myList = new ArrayList(Arrays.asList(“a”,”b”,”c”)); title &amp;&amp; descriptiontitle 和 description 用于描述一个属性，当我们指定了这两个参数时，jsonschema2pojo会在属性的上面生成 Java 文档，并且title在description之上。 formatformat 是jsonschema2pojo 提供给我们扩展更多类型的一个参数，在上面介绍的type中可以看到我们生成的 Java 类型并不多，像 Date 等这些参数都没有，但是当我们加上 jsonschema2pojo能识别的format参数后，就可以扩展我们的属性类型，具体参照： Format value Java Type “date-time” java.util.Date “date” String “time” String “utc-millisec” long “regex” java.util.regex.Pattern “color” String “style” String “phone” String “uri” java.net.URI “email” String “ip-address” String “ipv6” String “host-name” String “uuid” java.util.UUID extends使用extends关键字可以实现 Java 中的继承。比如，我们定义 flower.json 123{ &quot;type&quot; : &quot;object&quot;} 然后定义 rose.json，使其继承自 flower 123456{ &quot;type&quot; : &quot;object&quot;, &quot;extends&quot; : { &quot;$ref&quot; : &quot;flower.json&quot; }} 最终我们生成的 Rose.java 为以下内容： 123public class Rose extends Flower { ....} $ref$ref关键字用于指定某一个属性的引用来源，在jsonschema2pojo中支持以下协议： http://, https:// file:// classpath:, resource:, java: (all synonyms used to resolve schemas from the classpath). 我们定义 API 的时候一般是需要引用到其他我们定义的 Json Schema 文档。比如： 12345678{ &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;loggedInUser&quot; : { &quot;$ref&quot; : &quot;user.json&quot; } }} 表明loggedInUser属性的类型是一个由user.json定义的类型。 123456789101112{ &quot;description&quot; : &quot;Tree node&quot;, &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;children&quot; : { &quot;type&quot; : &quot;array&quot;, &quot;items&quot; : { &quot;$ref&quot; : &quot;#&quot; } } }} 这个表明 children 属性引用的是该 object 自身，所以这可以生成一个 Tree 类型的类。 1234567public class TreeNode { public List&lt;TreeNode&gt; getChildren() { ...} public void setChildren(List&lt;TreeNode&gt; children) { ...}} 更多 javaEnumNames 12345678910{ &quot;type&quot; : &quot;object&quot;, &quot;properties&quot; : { &quot;foo&quot; : { &quot;type&quot; : &quot;string&quot;, &quot;enum&quot; : [&quot;H&quot;,&quot;L&quot;], &quot;javaEnumNames&quot; : [&quot;HIGH&quot;,&quot;LOW&quot;] } }} 生成的类： 12345public enum Foo { HIGH(&quot;H&quot;), LOW(&quot;L&quot;) ...} javaInterfaces 1234{ &quot;javaInterfaces&quot; : [&quot;java.io.Serializable&quot;, &quot;Cloneable&quot;], &quot;type&quot; : &quot;object&quot;} 生成的类： 123public class FooBar implements Serializable, Cloneable{... javaName 123456789{ &quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: { &quot;a&quot;: { &quot;javaName&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot; } }} 生成的类： 1234567891011121314public class MyClass { @JsonProperty(&quot;a&quot;) private String b; @JsonProperty(&quot;a&quot;) public String getB() { return b; } @JsonProperty(&quot;a&quot;) public void setB(String b) { this.b = b; }}声明 本文绝大部分内容是引用的 jsonschame2pojo 的文档，更多内容请看官方文档 jsonschema2pojo.","link":"/2019/06/25/使用-Json-Schema-定义-API/"},{"title":"使用 Docker 构建你的 Spring Boot 程序","text":"很多人都使用容器来包装他们的 Spring Boot 应用程序，然而创建容器并不是一件很容易的事情。这篇文章将指导你构建运行 Spring Boot 应用程序的Docker镜像。 对于我们开发者来说，容器不是一个好理解的概念 – 它会强迫我们了解并考虑非常低级的问题 – 但是有些时候我们需要创建或使用容器，因此我们理解下构建块的内容是有必要的。 在这篇文章中，我会向你展示创建容器的一些知识，你可以针对你的应用程序作出适当地选择。 Docker 是一个具有“社交”方面的 Linux 容器管理工具，它允许用户发布容器镜像，以及使用其他人发布的镜像。Docker 镜像是一个运行容器化进程的“食谱”，接下来，我将构建一个简单的 Spring Boot 应用程序的镜像。 在此之前，你需要安装一下 Docker。（Docker）如果你使用的系统是 Windows，你需要安装 Docker Desktop。（Docker Desktop） 创建 Gradle 工程首先，我们使用 IDEA 创建一个 Gradle 工程。然后，在 build.gradle 文件中加入以下内容： 1234567891011121314151617181920212223242526272829buildscript { repositories { mavenCentral() } dependencies { classpath(\"org.springframework.boot:spring-boot-gradle-plugin:2.1.6.RELEASE\") }}apply plugin: 'java'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'bootJar { baseName = 'spring-boot-docker' version = '0.1.0'}repositories { mavenCentral()}sourceCompatibility = 1.8targetCompatibility = 1.8dependencies { compile(\"org.springframework.boot:spring-boot-starter-web\") testCompile(\"org.springframework.boot:spring-boot-starter-test\")} 在 Gradle 构建文件中，我们使用了 Spring Boot Gradle 插件，它可以提供很多便利的特性： 它可以收集环境变量中的所有的 jar，然后将它们构建成一个简单的，可运行的“über-jar”。（über 是一个德文单词，可理解为总）这使得执行和传输服务变得更加方便。 它会搜索 public static void main() 方法，并将它标记为一个可运行的类。 它提供了一个内置的依赖解决工具，可以设置 Spring Boot 依赖的版本号。你可以用你想要的版本进行覆盖，但是它默认为 Spring Boot 选择的版本。 创建 Spring Boot 应用我们在工程中创建一个 Application 类，作为 Spring Boot 的启动类，同时也作为一个 Controller 类。 Application.java123456789101112@SpringBootApplication@RestControllerpublic class Application { @RequestMapping(\"/\") public String home() { return \"Hello Docker World\"; } public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 现在我们可以运行一下 Spring Boot 程序，可以直接在 IDEA 中运行，也可以使用以下命令运行 ./gradlew build &amp;&amp; java -jar build/libs/spring-boot-docker-0.1.0.jar。（Windows：gradlew build &amp;&amp; java -jar build/libs/spring-boot-docker-0.1.0.jar） 运行成功后，我们访问 localhost:8080，可以看到页面会显示“Hello Docker World”。 制作 Docker 镜像我们在上面的 Gradle 构建文件中有一个任务 bootJar，此任务会在 build/libs 下生成可运行的 jar 包 spring-boot-docker-0.1.1.jar。接下来我们使用此 jar 文件制作一个 Docker 镜像。 首先，我们编写 Dockerfile。 12345FROM openjdk:8-jdk-alpineVOLUME /tmpARG JAR_FILECOPY ${JAR_FILE} app.jarENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"] 这个 Dockerfile 非常简单，但是你需要运行一个没有多余装饰的 Spring Boot 项目：仅仅使用 Java 和 一个 JAR 文件。项目的 JAR 文件作为 “app.jar” 被添加进容器，然后在 ENTRYPOINT 中执行。 然后我们运行 docker 命令制作 docker 镜像： docker build --build-arg JAR_FILE=build/libs/*.jar -t myorg/myapp . 如果运行失败，并且日志显示如下： 1...... This error may also indicate that the docker daemon is not running. 说明我们的机器没有启动 Docker，需要把 Docker 启动后再运行，在 Windows 上运行的是 Docker Desktop。 制作镜像成功后，我们可以运行命令查看当前我们的 Docker 中的镜像：docker images，显示如下： 1234$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmyorg/myapp latest 4979c9dc93c3 About a minute ago 122MBopenjdk 8-jdk-alpine a3562aa0b991 3 months ago 105MB 可以看到，我们创建的镜像 myorg/myapp 已经成功了，然后我们运行此镜像：docker run -p 8080:8080 myorg/myapp，显示如下： 1234567891011121314151617181920212223$ docker run -p 8080:8080 myorg/myapp . ____ _ __ _ _ /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.6.RELEASE)2019-08-13 09:27:13.796 INFO 1 --- [ main] com.tryking.docker.Application : Starting Application on fbe1e74d4885 with PID 1 (/app.jar started by root in /)2019-08-13 09:27:13.800 INFO 1 --- [ main] com.tryking.docker.Application : No active profile set, falling back to default profiles: default2019-08-13 09:27:15.276 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2019-08-13 09:27:15.322 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2019-08-13 09:27:15.322 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.21]2019-08-13 09:27:15.433 INFO 1 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2019-08-13 09:27:15.434 INFO 1 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1567 ms2019-08-13 09:27:15.718 INFO 1 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService &apos;applicationTaskExecutor&apos;2019-08-13 09:27:15.946 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &apos;&apos;2019-08-13 09:27:15.950 INFO 1 --- [ main] com.tryking.docker.Application : Started Application in 2.688 seconds (JVM running for 3.309)2019-08-13 09:27:26.452 INFO 1 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet &apos;dispatcherServlet&apos;2019-08-13 09:27:26.453 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet &apos;dispatcherServlet&apos;2019-08-13 09:27:26.458 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 5 ms 这里，我们的 Docker 镜像就制作成功了，可以访问 localhost:8080 看一下结果是否正常。 使用命令查看 docker 镜像运行是否正常： docker ps 123$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfbe1e74d4885 myorg/myapp &quot;java -jar /app.jar&quot; 8 minutes ago Up 8 minutes 0.0.0.0:8080-&gt;8080/tcp nostalgic_hermann 可以看到我们的 docker 正在正常运行，并且已经运行了 8 分钟。 到目前为止，我们的 docker 配置非常简单，生成的镜像也非常低效。Docker 镜像只有一个单独的文件系统层，里面包含了一整个 jar，我们每次更改代码的时候，都会直接更改到这层，这会导致这层占用空间非常大。我们可以改进一下，把这个 JAR 包分成多层。 更小的镜像我们前面采用的基础镜像是 openjdk:8-jdk-alpine，alpine 镜像比 Dockerhub 提供的标准的 openjdk 镜像更小。 目前还没有针对 Java 11 的官方 alpine 镜像。你还可以在基础镜像中通过使用 jre 标签代替 jdk来节省大约 20 MB 的空间。虽然并不是所有的应用使用 JRE 就能工作（相对于 JDK），但是大部分应用都可以。实际上，由于对 JDK 特性滥用的风险存在（比如编译），一些组织会强制执行对于每个 APP 必须遵守的规则。 最后，对于镜像构建有一个非常重要的问题：我们的目标不总是要构建尽可能小的镜像。较小的镜像上传和下载速度比较快，这固然好，但是这也有个前提：它们中的任何层都没有被缓存。镜像注册非常复杂，你可以通过尝试巧妙地使用图像构造来轻松地失去这些功能的好处。如果你使用公共基础层，你根本不需要担心镜像的总大小，并且随着注册和平台的发展，镜像可能会变得更小。话说回来，尝试优化我们应用的镜像的层仍然是非常重要以及有效的，但是我们的目标应该始终是将最快速变化的东西放在最高层，并与其他程序共享尽可能多的大型较低层。 优化的 Dockerfile由于 Spring Boot fat jar 的打包方式，它自然就有多层这个概念。我们解压 jar 包后可以发现，它里面早已分成了外部和内部依赖。要在 docker 构建中执行此操作，我们需要先解压 jar 包。例如： 123$ mkdir build/dependency$ cd build/dependency/; jar -xf ../libs/*.jar$ docker build -t myorg/myapp . 对应的 Dockerfile 为： 1234567FROM openjdk:8-jdk-alpineVOLUME /tmpARG DEPENDENCY=build/dependencyCOPY ${DEPENDENCY}/BOOT-INF/lib /app/libCOPY ${DEPENDENCY}/META-INF /app/META-INFCOPY ${DEPENDENCY}/BOOT-INF/classes /appENTRYPOINT [\"java\",\"-cp\",\"app:app/lib/*\",\"com.tryking.docker.Application\"] 现在我们的 docker 镜像有三层了，后面的两层包含所有的应用程序资源。如果应用的依赖不做更改，那么第一层（来自 `BOOT-INF/lib）将不会变动，因此构建将会非常快，只要基础层已经被缓存过，容器在运行时的启动也是如此。 我们使用了硬编码指定应用的启动类 com.tryking.docker.Application。在这里我们还可以将 Spring Boot fat JarLauncher 复制进镜像，然后使用它来启动应用，这样就不需要指定 main 类了，但是它可能会拖慢速度。 微调如果我们想要让应用启动速度尽可能快，有一些微调我们可以用到。下面是一些方法： 使用 spring-context-indexer。对于小型程序来说它可能增加不了太多，但是苍蝇再小也是肉。 如果可以的话，尽量不要使用执行器 actuators。 使用 Spring Boot 2.1 以及 Spring 5.1。 使用 spring.config.location（命令行参数或系统属性） 代替 Spring Boot 默认的配置文件地址。 关闭 JMX - 在容器中你可能不需要它。命令：spring.jmx.enabled=false 使用 -noverify 运行 JVM。还要注意： -XX:TieredStopAtLevel=1 （这个虽然会节约启动时的时间，但是后面会导致 JIT 的速度减慢） 对于 Java 8， 使用容器内存提示：-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap。在 Java 11 中，这些已经被默认设置了。 我们的应用程序可能运行的时候不需要完整的 CPU，但是它需要多个 CPU 才能尽可能快地启动（至少 2 个，4 个更好）。如果我们不介意启动速度较慢，可以将 CPU 降到 4 个以下。如果我们被迫以少于 4 个 CPU 启动，我们可以设置 Dspring.backgroundpreinitializer.ignore = true，因为它会阻止 Spring Boot 创建一个它可能无法使用的新线程。（这个适用于 Spring Boot 2.1.0 及以上版本） Docker 构建插件如果我们在构建中不想直接调用 docker 命令，有很多 Gradle 插件可以帮我们做这些，下面介绍一些。 Palantir Gradle PluginPalantir Gradle Plugin 插件和 Dockerfile 一起工作，它也可以为我们生成一个 Dockerfile，然后它会运行 docker，就像我们自己在命令行中运行一样。 首先，我们需要在 build.gralde 中引入： build.gralde123456789101112buildscript { repositories { maven { url \"https://plugins.gradle.org/m2/\" } mavenCentral() } dependencies { ... classpath('gradle.plugin.com.palantir.gradle.docker:gradle-docker:0.13.0') }} 最后，我们需要应用此插件然后调用它的任务： build.gralde12345678910111213141516171819apply plugin: 'com.palantir.docker'group = 'myorg'bootJar { baseName = 'myapp' version = '0.1.0'}task unpack(type: Copy) { dependsOn bootJar from(zipTree(tasks.bootJar.outputs.files.singleFile)) into(\"build/dependency\")}docker { name \"${project.group}/${bootJar.baseName}\" copySpec.from(tasks.unpack.outputs).into(\"dependency\") buildArgs(['DEPENDENCY': \"dependency\"])} 在此示例中，我们选择在解压 Spring Boot 的 fat jar 到一个 build 目录下的特定位置，这里是 docker 构建的根目录。然后上面的多层（multi-layer，不是 multi-stage） Dockerfile 就会工作了。 Jib Gradle Plugin参照 Jib 持续集成自动化现在是（或者应该是）每个应用程序的一部分。人们用来进行自动化的工具往往非常擅长从源代码中调用构建系统。因此，如果有一个 Docker 镜像，并且构建代理中的环境与开发人员的环境一致，这对于我们来说就足够了。对 docker 注册表进行身份验证对我们来说可能是最大的挑战，但是所有的自动化工具中都有一些功能可以帮助我们解决这个问题。 但是，有时我们最好将容器的创建完全留给自动化层，这样可以保证我们的代码不需要被污染。容器创建是一个棘手的问题，我们开发人员往往并不关心它。如果我们的代码更加整洁，那么不同的工具将更有可能做到“做正确的事”，比如应用安全修复，优化缓存等。自动化有很多选择，如今他们都会带一些与容器化相关的功能。接下来我们看一下 Jenkins。 JenkinsJenkins 是一个非常流行的自动化服务。它有很多特性，但是最接近其他自动化示例的是它的 pipeline 功能。下面是一个 Jenkinsfile，它会使用 maven 构建一个 Spring Boot 工程，然后使用 Dockerfile 构建一个镜像并把它们推送到仓库中。 Jenkinsfile12345node { checkout scm sh &apos;./mvnw -B -DskipTests clean package&apos; docker.build(&quot;myorg/myapp&quot;).push()} 结语本文提供了很多用于为 Spring Boot 应用构建容器镜像的选项。所有的内容都是有效的选择，现在由你自己决定需要哪个。你的第一个问题应该是“我真的需要建立一个容器镜像吗？”如果答案是确定的，那你的选择可能要尽可能考虑效率和可缓存性等。 标题：使用 Docker 构建你的 Spring Boot 程序作者：末日没有进行曲链接：link时间：2019/08/16声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/16/使用-Docker-构建你的-Spring-Boot-程序/"},{"title":"使用 Mockito 的一些坑","text":"今天使用 Mockito 遇到一个匪夷所思的问题。 我们知道，在使用 Mockito 的时候，如果要 Mock 一个方法，需要将其参数也传对，只有参数匹配上了，才能 Mock 到位。 比如，我今天 Mock 的一个方法是这样的： 12345Class CallClass { public String callMethod(Class A, Class B){ ... }} 在代码中调用： 12CallClass c = new CallClass();c.callMethod(A, null); 注意，我在代码中调用方法时对于 B 传入的是一个 null。 然后开始写测试方法了，在测试方法中我 Mock 了 CallClass 方法。 通过以下方式将代码中引用的对象 CallClass 替换掉。 12345678910import static org.mockito.ArgumentMatchers.any;...@Mockprivate CallClass callClass;Field cc = *.getClass().getDeclaredField(c);`cc.setAccessible(true);cc.set(*, callClass); 然后再给方法打桩： 1234String mockStr = \"mock\";when(callClass.callMethod(any(A.class), any(B.class)).thenReturn(mockStr); 结果，在代码调用中返回的结果怎么都不是我想要的 mockStr 的结果，甚是郁闷。 经过我的试错大法，最终终于发现了问题所在，null 并不能匹配 any(B.class)，这里应该使用的是 ArgumentMatchers.&lt;B&gt;any()，即 1when(callClass.callMethod(any(A.class), ArgumentMatchers.&lt;B&gt;any()).thenReturn(mockStr); 看来还是对 Mockito 的文档不是很熟悉，每次都是现用现查，现在尝到苦果了。 标题：Title作者：末日没有进行曲链接：link时间：2020-03-17声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/03/17/使用-Mockito-的一些坑/"},{"title":"使用 PowerMockito 测试","text":"PowerMockito 是 Powermock 集成的 Mockito2 ，可以用来模拟对象进行测试。 首先，我们需要添加依赖。 12testCompile &apos;org.powermock:powermock-module-junit4&apos;testCompile &apos;org.powermock:powermock-api-mockito2&apos; Mock 方法测试方法： 12345public class Math { public int add(int i, int j) { return i + j; }} 假如我们需要让上面的 add(int i, int j) 方法无论传入什么参数，都返回固定的值，我们可以这样做。 123456789101112public class MathTest { @Test public void test() { Math math = new Math(); int original = math.add(4, 5); System.out.println(\"original:\" + original); final Math spyMath = PowerMockito.spy(math); PowerMockito.when(spyMath.add(anyInt(), anyInt())).thenReturn(0); System.out.println(\"spy:\" + spyMath.add(4, 5)); }} 控制行将会打印以下日志： 12original:9spy:0 Mock 静态方法 标题：使用 PowerMockito 测试作者：末日没有进行曲链接：link时间：2019-11-07声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/11/07/使用-PowerMockito-测试/"},{"title":"使用 Spring Actuator + Prometheus + Grafana 监控系统","text":"Spring Boot 有个 Actuator，它可以为应用提供强大的监控能力。从 Spring Boot 2.0 开始，Actuator 将底层更改为了 Micrometer，使得 Actuator 能提供更加强大，更加灵活的监控能力。Micrometer 是一个类似门面的监控系统，可以把它看做是监控界的 Slf4j。 借助 Micrometer，我们的应用可以对接各种各样的监控系统。在这篇文章这种，我们演示下如何对接 Prometheus，对接完 Prometheus后，我们使用 Grafana 来实现数据的可视化效果。 集成 Prometheus增加依赖首先，我们创建 Spring Boot 项目，并增加以下依赖。 1234dependencies { implementation &apos;org.springframework.boot:spring-boot-starter&apos; implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos; implementation &apos;io.micrometer:micrometer-registry-prometheus&apos; 在这里，我们引入了 micrometer-registry-prometheus，引入后 Micrometer 便可以对接 Prometheus。 写配置在 application.yml 中增加以下配置： 12345678910111213server: port: 8080spring: application: name: prometheus-testmanagement: endpoints: web: exposure: include: &apos;prometheus&apos; metrics: tags: application: ${spring.application.name} 测试启动应用，然后访问 http://localhost:8080/actuator/prometheus，可以得到如下结果： 12 标题：[使用 Spring Actuator + Prometheus + Grafana 监控系统](https://dengkaiting.com/2019/12/23/使用 Spring Actuator + Prometheus + Grafana 监控系统)作者：末日没有进行曲链接：link时间：2019-12-23声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/12/23/使用-Spring-Actuator-Prometheus-Grafana-监控系统/"},{"title":"使用 Spring Boot & Mockito 进行 Java Unit Testing - 使用 Mockito 进行 Mocking","text":"单元测试(Unit Testing) 是我们日常开发中非常重要的一环，这篇文章我将告诉大家如何使用 Spring Boot 和 Mockito 进行测试。 使用 Spring Initializr 创建工程Spring Initializr 可以非常方便地帮助我们创建 Spring Boot 程序，我们只需要选择我们需要的内容生成 zip 压缩包，然后将压缩包导入到 IDEA 中即可。 图片 这里，我们仅需要 Spring Web，选择 Spring Boot DevTools 更加利于我们开发。 选择完成后，我们导出项目，然后导入到 IDE 中。 对一个简单的业务服务写单元测试我们写一个简单的业务方法，然后对其进行测试。 12345678910public class SomeBusinessImpl { public int calculateSum(int[] data) { int sum = 0; for (int value : data) { sum += value; } return sum; }} 测试方法（在 IDEA 中，在业务方法中使用快捷键 Shift + Ctrl + T 可以快速生成测试方法）： 1234567891011121314151617181920212223@Testpublic void calculateSum_basic() { SomeBusinessImpl business = new SomeBusinessImpl(); int actualResult = business.calculateSum(new int[] { 1, 2, 3 }); int exceptedResult = 6; assertEquals(exceptedResult, actualResult);}@Testpublic void calculateSum_empty() { SomeBusinessImpl business = new SomeBusinessImpl(); int actualResult = business.calculateSum(new int[] {}); int exceptedResult = 0; assertEquals(exceptedResult, actualResult);}@Testpublic void calculateSum_oneValue() { SomeBusinessImpl business = new SomeBusinessImpl(); int actualResult = business.calculateSum(new int[] { 3 }); int exceptedResult = 3; assertEquals(exceptedResult, actualResult);} 在测试方法中，我们分别对基本的数组，空数组以及仅有一个元素的数组进行了测试，运行测试方法，可以看到测试方法均能正常通过。 创建一个调用 Data Service 的业务服务 标题：使用 Spring Boot & Mockito 进行 Java Unit Testing - 使用 Mockito 进行 Mocking作者：末日没有进行曲链接：link时间：1581302118000声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/02/10/使用-Spring-Boot-Mockito-进行-Java-Unit-Testing-使用-Mockito-进行-Mocking/"},{"title":"前端小技能复盘","text":"主业虽然不是前端，但是经常会因为工作需要去写一些前端。每次写前端都比较痛苦，因为不熟练，一个小的 js 方法都需要每次去网上找，特将最近遇到的前端技能进行一下复盘，以备后用。 Form 表单 form 表单 submit 时，默认只有含有 name 属性的元素才会被 submit。 给 Table 动态添加数据 HTML 1234567891011121314151617181920212223242526272829&lt;table id=\"testTable\" class=\" table order-list\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;td&gt;product&lt;/td&gt; &lt;td&gt;type&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class=\"col-sm-3\"&gt; &lt;input type=\"text\" name=\"product_0\" class=\"form-control\" id=\"product_0\" value=\"Desk\"/&gt; &lt;/td&gt; &lt;td class=\"col-sm-2\"&gt; &lt;select class=\"typeahead form-control\" name=\"type_0\" id=\"type_0\"&gt; &lt;option selected&gt;SYSTEM&lt;/option&gt; &lt;option&gt;CUSTOM&lt;/option&gt; &lt;/select&gt; &lt;/td&gt; &lt;td&gt; &lt;input type=\"button\" class=\" btn btn-md btn-info \" id=\"addRow\" value=\"Add Row\"&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;tfoot&gt; &lt;tr&gt; &lt;/tr&gt; &lt;/tfoot&gt;&lt;/table&gt; JavaScript 1234567891011121314151617181920212223&lt;script&gt; counter = 1; $(\"#addRow\").bind(\"click\", addRowClick); function addRow() { var newRow = $(\"&lt;tr&gt;\"); var cols = \"\"; var product = \"product_\" + counter; var type = \"SYSTEM\"; cols += '&lt;td&gt;&lt;input type=\"text\" class=\"form-control\" value=\"' + product + '\" name=\"location_' + counter + '\" id=\"location_' + counter + '\"/&gt;&lt;/td&gt;'; cols += '&lt;td&gt;&lt;select class=\"typeahead form-control\" value=\"' + type + '\" name=\"type_' + counter + '\" id=\"type_' + counter + '\"&gt;' + '&lt;option selected&gt;SYSTEM&lt;/option&gt;' + '&lt;option&gt;CUSTOM&lt;/option&gt;' + '&lt;/select&gt;&lt;/td&gt;'; cols += '&lt;td&gt;&lt;input type=\"button\" class=\"ibtnDel btn btn-md btn-danger \" value=\"Delete\" id=\"delete_' + counter + '\"&gt;&lt;/td&gt;'; newRow.append(cols); $(\"table.order-list\").append(newRow); counter++; } $(\"table.order-list\").on(\"click\", \".ibtnDel\", function (event) { $(this).closest(\"tr\").remove(); });&lt;/script&gt; 其他 数组可以直接用以下方法进行遍历： 123arr.forEach(function(obj){ // do something for obj}) 值得注意的是，如果我们在一个方法中使用了 forEach，并且我们想在遍历到某个元素 return 的话是不可行的。 解析 Json 123var json = JSON.parse( data + \"\" );var jsonStr = JSON.stringify(json); 向 Arr 中添加数据 1arr.push(item) 点击链接，在新页面打开，需要给 &lt;a&gt; 元素添加以下属性 1&lt;a href=\"https://www.baidu.com\" target=\"_blank\"&gt;open baidu&lt;/a&gt; 延迟一定时间后执行某个方法 1setTimeout(function () { alert('sleep 1s'); }, 1000); 标题：前端小技能复盘作者：末日没有进行曲链接：link时间：2019-08-04声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/08/04/前端小技能复盘/"},{"title":"听说你的腾讯云/阿里云主机访问不了 Github？","text":"怎么解决访问 Github 问题？ 因为博客部署在腾讯云主机上，某次上服务器更新博客时，发现出现如下提示：fatal: unable to access 'https://github.com/Tryking/tryking.github.io.git/': Encountered end of file 诺？网络又被墙了，因为这台主机平时只做博客服务器，因此也懒得放科学工具了，那么有什么好的办法可以解决这个问题吗？ 因为 Github 在全球都有服务器，我们是不是可以找一个腾讯云可以访问的地址替换掉自动解析的地址呢？ 说干就干，首先访问一个ip查询工具，这里使用 https://github.com.ipaddress.com/，然后分别查询 github.com 和 github.global.ssl.fastly.net 对应的 IP。 编辑主机的 hosts 文件，vim /etc/hosts，将查到的结果添加进去。 12140.82.112.3 github.com199.232.69.194 github.global.ssl.fastly.net 再进行 git pull，嗯，代码成功拉下来了，这个方法临时用下还不错。 标题：听说你的腾讯云/阿里云主机访问不了 Github？作者：末日没有进行曲链接：听说你的腾讯云/阿里云主机访问不了 Github？时间：2021-03-19声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2021/03/19/听说你的腾讯云-阿里云主机访问不了-Github？/"},{"title":"在 Log4j2 中使用 JsonLayout 输出 Json 格式的日志","text":"如果我们需要将日志集成到 ELK 中，当日志格式是 Json 的时候，会方便我们的解析。幸运地是，Log4J2 中提供了 Json 这种格式的日志 Layout。当我们设置 Layout 为 JsonLayout 时，此时生成的日志就是 Json 格式。 使用JsonLayout 的使用方式如下。 首先我们创建 log4j2.xml 文件。我们只是将 PatternLayout 换成了 JsonLayout。 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Configuration&gt; &lt;Appenders&gt; &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt; &lt;JsonLayout/&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=\"info\"&gt; &lt;AppenderRef ref=\"Console\"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 然后我们还需要添加 Jackson 的依赖（log4j2 的依赖当然也不能少）： 1compile group: &apos;com.fasterxml.jackson.core&apos;, name: &apos;jackson-databind&apos;, version: &apos;2.10.1&apos; 最后，我们编写测试代码。 123456public class testLog { final static Logger logger = LogManager.getLogger(testLog.class); public static void main(String[] args) { logger.info(\"test log\"); }} 运行代码后，我们可以看到控制台输出的日志： 1234567891011121314{ &quot;thread&quot; : &quot;main&quot;, &quot;level&quot; : &quot;INFO&quot;, &quot;loggerName&quot; : &quot;testLog&quot;, &quot;message&quot; : &quot;test log&quot;, &quot;endOfBatch&quot; : false, &quot;loggerFqcn&quot; : &quot;org.apache.logging.log4j.spi.AbstractLogger&quot;, &quot;threadId&quot; : 1, &quot;instant&quot; : { &quot;epochSecond&quot; : 1577265222, &quot;nanoOfSecond&quot; : 33000000 }, &quot;threadPriority&quot; : 5} 可以看到，日志将 thread 等关键信息都打印出来了。但是，这里时间显示的时间戳好像有点不友好，后面我们将打印新的格式化后的时间。 参数设置JsonLayout 还提供了很多参数设置。 参数名 类型 描述 charset String 转换成一个 byte 数组时使用的字符集。改值必须是一个合法的 Charset。如果没有指定，将默认使用 UTF-8。 compact boolean 如果设置为 true，appender 将不使用行尾换行，并且会对Json日志进行压缩。默认为 false。 eventEol boolean 如果设置为 true，appender 将在每条记录后 appender 一个行尾换行，默认为 false。使用 eventEol=true 以及 compact=true 可以让每条日志独占一行。 endOfLine String 如果设置了，会覆盖默认的行尾字符串。例如，设置它为“\\n”，并且设置 eventEol=true,compact=true，每行结果将被”\\n” 分隔（代替 \\t\\n）。默认是 null（不设置）。 complete boolean 如果设置为 true，appender 将包含Json 的 header ， footer以及每条日志间的逗号，默认为 false。 properties boolean 如果设置为 true，appender 将在生成的 Json 中包含线程上下文 map 信息，默认是 false。 propertiesAsList boolean 如果设置为 true，线程上下文map将作为一个map 实体对象列表。每个实体对象有一个“key”属性和一个“value”属性。默认为 false，这种情况下，线程上下文map是一个简单的key-value对的map。 locationInfo boolean 如果设置为 true，appender 将在生成的 Json 中包含 location 信息，默认是 false。生成 location information 是一个比较耗能的操作，可能会影响性能，应当谨慎使用。 includeStacktrace boolean 如果设置为 true，将输出 Throwable 的完整堆栈。（可选，相当于打印出异常，默认为true ） stacktraceAsString boolean 是否将堆栈信息格式化为 string，而不是嵌套的对象。（可选，默认为false） includeNullDelimiter boolean 每次事件完成后是否包含 NULL 字节。（可选，默认为 false）。 objectMessageAsJsonObject boolean 如果设置为 true。ObjectMessage 将被序列化为一个Json对象放到 输出日志的“message” 域中，默认是 false。 添加格式化展示时间日志对于 JsonLayout， 可以添加子元素 KeyValuePair 来增加更多的属性。比如，我们想添加一个格式化时间的话，我们只需要添加一个 KeyValuePair。 123&lt;JsonLayout&gt; &lt;KeyValuePair key=\"timestamp\" value=\"$${date:yyyy-MM-dd-HH:mm:ss.SSSSS}\"/&gt;&lt;/JsonLayout&gt; 打印对象我们在程序中有时需要将对象打印出来，在 Log4J 中也是支持直接打印对象的。 123456789101112131415161718192021222324252627282930313233public class testLog { final static Logger logger = LogManager.getLogger(testLog.class); final static Marker MARKER_WHITESPACE = MarkerManager.getMarker(&quot;ANA_WHITESPACE&quot;); public static void main(String[] args) { final Person person = new Person(); person.name = &quot;Jack&quot;; person.isMan = true; logger.info(&quot;test log&quot;); // 会将对象打印出来。 logger.info(MARKER_WHITESPACE, person); logger.info(MARKER_WHITESPACE, person.toString()); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put(&quot;orig&quot;, &quot;msg_origValue&quot;); // 会将对象打印出来。 map.put(&quot;person&quot;, person); logger.info(MARKER_WHITESPACE, map); } static class Person { String name; boolean isMan; @Override public String toString() { return &quot;Person{&quot; + &quot;name=&apos;&quot; + name + &apos;\\&apos;&apos; + &quot;, isMan=&quot; + isMan + &apos;}&apos;; } }} 标题：在-Log4j2-中使用-JsonLayout-输出-Json-格式的日志作者：末日没有进行曲链接：link时间：2019-12-25声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/12/25/在-Log4j2-中使用-JsonLayout-输出-Json-格式的日志/"},{"title":"如何使用 GitHub Pages 维护自己的博客","text":"前置知识首先，你应该知道如何用 Hexo 在本地搭建一个博客系统，具体见 Hexo。 其次，我们如果想使用 GitHub Pages 搭建自己的博客只需要在 GitHub 创建一个名为***.github.io的 repository，其中***代表你 GitHub 的名字。然后将我们要展示的静态文件放到此 repository 的master分支下即可，具体见 Websites for you and your projects.。 搭建完毕之后，你需要了解 Hexo 发布博客的基本步骤，主要使用以下几个命令： hexo generate 简写为 hexo g：此命令可以生成我们需要展示博客内容的静态文件。当我们写完自己的博客内容后，运行此命令可以把博客内容需要的静态文件放到目录 public 下。 hexo server：此命令可以在当前服务器（也就是你当前操作的电脑）启动博客服务，默认访问地址为：http://localhost:4000/。 到这里，我们就知道如何用 GitHub Pages 维护博客了，我们只需要把使用hexo g生成的静态文件放到我们创建的 ***.github.io 的 master 分支下即可以用域名 ***.github.io 来展示我们的博客内容了。 但是难道我们就只能这样手动去不断 copy 吗？当然不用，这里还需要知道的是 Hexo 支持自动将本地写的博客内容部署到服务器（如果使用 GitHub Pages，服务器指的就是自己的 Git repository），支持的类型有多种：Git, Heroku, Netlify, Rsync, SFTP 等，具体见 Hexo 自动部署，我们只使用 Git 类型即可。 实际操作我们写博客基本上不可能是只在一台机器上进行写作、部署，当我们使用不同的电脑时，如何进行便捷的同步操作呢？其实，我们完全可以使用我们创建的 ***.github.com repository 来进行操作管理，我们最终展示的内容是放在 master 分支的，所以我们需要创建一个新的分支来保存我们写作的博客内容，即 Hexo 相关的东西。 在这里，我使用分支 hexo 来保存博客内容，当我们在 hexo 分支下把内容编辑完后，使用命令 hexo deploy 即可将生成的静态文件自动发布到 ***.github.com repository 中的 master 分支中，稍等数秒，访问 ***.github.com 即可以看到我们博客的更新了。 当我们使用别的机器更新博客时也是同样的操作，把 repository clone 到你想更新的机器上，使用 hexo 分支进行内容的编写，写完测试通过后直接 hexo deploy 即可。","link":"/2019/06/08/如何使用-GitHub-Pages-维护自己的博客/"},{"title":"如何使用 IDEA 开发 Play 项目","text":"Play 是一个非常优秀的 web 开发工具，你知道如何使用 IDEA 进行开发吗？ 在 IDEA 中开发 Play 项目时，默认是不会自动导入 Play 的依赖的，我们需要把 Play 的依赖导入，主要包括 Play 的 jar 包以及它的 libs。 打开 Project Settings，可以看到我们的依赖中没有 Play 相关的内容， 我们需要导入。 我们点击上图中右边的 + 号，选择 JARs or directories，然后找到我们的 Play 所在目录，分别将 lib 和 play.jar 导入。 接着，我们打开 Run/Debug Configurations，配置一个 Play 的启动命令。 我们在 Main class 中输入 play 的启动路径 play.server.Server。 好了，愉快地享受 Play 吧。 标题：Title作者：末日没有进行曲链接：link时间：1581515683000声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/02/12/如何使用-IDEA-开发-play-项目/"},{"title":"如何才能更好地成长","text":"你觉得怎样才能更好地成长？ 对自己高标准要求德国是一个非常注重质量的国家，尤其是在汽车制造领域，像奔驰，保时捷，奥迪等好多一线品牌的汽车都出自德国。德国的企业对产品标准要求非常高，这也是众多品牌能杀出世界的一个关键因素。 在德国一家培训公司中，专门培训锉刀的使用。在这些培训员中，大部分都是那些高中毕业没有去读大学的人。培训过程注重的就是对质量的把控，比如在他们使用锉刀磨铁块后，会用游标卡尺去测量铁块的长度，测量没有满足要求后再继续用锉刀进行打磨。 什么是游标卡尺呢？游标卡尺比我们平时使用的米尺更加精准，比如我们的米尺可以达到 1 毫米的精度，而游标卡尺能够精确到 0.1 毫米。这个精确度，用我们的肉眼根本是无法识别的。假设培训员用米尺来量，看到 36 毫米已经非常准了，但是用游标卡尺一量，可能是 35.6 毫米，离标准还差很多。 他们被要求使用游标卡尺，而不是直接肉眼看或者是用米尺，说明他们被训练在一个级别比较高的标准下做产品。假如我们用肉眼来量叫做 A 级别，用米尺来量叫做 B 级别，用游标卡尺来量叫做 C 级别，说明这家公司对这些培训员的要求是要做到 C 级别的，要求非常高。 为什么标准要做到这么高呢？因为很多产品对精确度的要求非常高，只有标准要求高了，才能做出好产品。比如我们做汽车的门，如果精确度不够，可能做出来的门要么是关不上，要么就是关上后会留一些细缝出来。只有精确度够了，门才能和车体严丝合缝，无论是在外观还是使用体验上，都会有质的变化。 只有不断提高标准，我们才能把自己的水平提高。在平时的工作生活中，如果我们总是用低水平的标准要求自己，就会导致自己和别人的差距越来越大。我们应该明白，为了更好地成长，我们需要用更高的标准来要求自己，不断地磨练。当我们在这个高标准之下都能完成任务的时候，在较低标准的环境中才能做到游刃有余。 多做一些难事不知大家发现没有，在我们工作比较久以后，对工作就会比较麻木，每天就是用自己的已经掌握的知识技能来进行工作，还感觉美滋滋的。随着时间的变化，你的技能树虽然不再增长了，但是社会这颗大树是会不断进步的，当你有一天突然发现自己的能力已经跟不上自己的岗位需求了，那时就欲哭无泪了。 这就像有两个果园，一个果园中的树是假树，没有生命，但是上面有比较多的果实。我们在果园中每天依靠这些果实就能生存，你每天的生活就是摘下这些果子，然后吃掉，感觉生活真是轻松美好。当这样一天一天过去后，你会发现树上的果实越来越少，之前只要伸手就能摘到果子，现在需要爬到树的顶端才能勉强够着一个了。终于有一天，你会发现树上根本就找不到一个果子了。 另外一个果园，里面的果树虽然个头比较小，数量比较少，但是他们都是有生命的，你可以进行悉心照料，直到多年后它们开始开花结果。在这之间，你可能需要对他们进行浇水、施肥、除害虫、剪枝。刚开始虽然你吃不到果子，但是随着时间的变化，这些果树越长越大，终于有一天你能吃到他们结出的果子了。在这之后，你就会有自己再也吃不完的果子了。 我们可以发现，如果我们把时间都花费在比较容易的事情上，到后面事情就会变得越来越难。但是如果我们把时间花费在早期比较难的事情上，后面往往就会变得比较容易。就是因为前面的困难导致了了后面的容易。 当然，为了生存我们也需要做一些比较简单的事情来维持生存。比如就是利用现有的技能进行工作来获取薪酬养活自己。与此同时，我们还需要把时间多花费在一些技能增长上，为未来做出准备。只有将简单和困难的事情组合着来做，才会在短期和长期都有稳定的输出。最怕的就是我们只做当前比较容易的事，不做那些利于自己将来的事，未来我们必定会被社会淘汰。 合理规划自己的生活我一般到公司都比较准时，在上家公司基本是8点多一点到，在现在的公司一般是8点50到。但是有时候我起床比较早，收拾好后还没有到达准备出发去公司的时候，我就会比较尴尬，这时候大多数情况下是拿出手机开始刷刷刷了。有一天我突然顿悟，这些时间都是被我杀掉了啊，为什么会这样？我认为就是没有合理规划好自己的生活。 我对于收拾好以及出发去公司这段 buffer 时间没有进行合理规划，因此到了那个时间点就会不知所措，以此只能用刷刷刷来杀时间。正确的做法是提前就对自己的生活进行规划，在哪个时间点应该做什么，如果某次某个事件花费的时间大大少于自己的规划时间，应该给那段 buffer 时间进行规划。加入有好多次都会出现这样的情况，那就是规划有问题了，需要进行重新规划。当然我现在做的也不是足够好，后面需要加强锻炼。 但是，我们还要明白：如果没有执行力，所有的规划都是空想。在规划好自己的生活后，我们还要有很强的执行力，这需要我们自己不断去培养。在这方面我自己做的也不是很 ok，经常就会对自己的规划进行食言，像健身，读书等等，哎，泪目。 道理简单，但是要做到并不容易，我们往往就是在这些细节方面和别人逐渐拉开了差距。希望我自己能在这三个方面做得更好，以获得更好地成长，也希望大家能更好地成长。 你觉得还需要做到什么才能更好地成长呢？","link":"/2019/06/29/如何才能更好地成长/"},{"title":"如何批量获取服务器的信息？","text":"有时我们需要批量获取服务器的信息，难道只能一台一台登录上去找吗？ 这里需要介绍一个神器 sshpass, sshpass 可以使用 ssh 登录服务器并且做一些操作，下面直接呈上脚本。 1234567891011121314151617181920212223242526#!/bin/bashinstances=`cat hosts`username=test_usernamepassword=test_passwordfor instance in ${instances[*]}; do echo ${instance} echo ${instance} &gt;&gt; result.txt ping_result=`ping -w 2 -c 3 ${instance} | grep packet | awk -F\" \" '{print $6}'| awk -F\"%\" '{print $1}'| awk -F' ' '{print $1}'` if [[ $ping_result -eq 0 ]]; then os_info=$(sshpass -p ${password} ssh -o StrictHostKeyChecking=no -l ${username} ${instance} 'cat /etc/redhat-release') echo ${os_info} &gt;&gt; result.txt tomcat_info=$(sshpass -p ${password} ssh -o StrictHostKeyChecking=no -l ${username} ${instance} 'ps aux | grep tomcat') tomcat_info=$(echo ${tomcat_info} | grep -Eo \"file=.*conf\") tomcat_info=$(echo ${tomcat_info/file=/}) tomcat_info=$(echo ${tomcat_info/\\/conf/}) echo ${tomcat_info} # echo ${tomcat_info} &gt;&gt; result.txt version_info=$(sshpass -p ${password} ssh -o StrictHostKeyChecking=no -l ${username} ${instance} \"${tomcat_info}/bin/version.sh\") echo ${version_info} | grep -Eo \"Server version:.*?Server\" echo ${version_info} | grep -Eo \"Server version:.*?Server\" &gt;&gt; result.txt echo \"------\" &gt;&gt; result.txt fidone hosts121.2.3.42.3.4.5 在脚本中，我们获取了服务器信息，以及 Tomcat 的版本信息。 标题：Title作者：末日没有进行曲链接：link时间：2020-02-20声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/02/20/如何批量获取服务器的信息？/"},{"title":"如何查看 Gradle 项目的依赖","text":"在 Gradle 项目中，有时候多个依赖包会造成冲突，那如何查看 Gradle 项目的依赖情况呢？ 使用命令 gradlew MODULE_NAME: dependencies 可以把该 MODULE_NAME 模块下的所有第三方类库以及其他模块的依赖情况打印出来，并且它能展示多中情况，比如 Compile 编译时，Runtime 时，Debug 时，以及 Release 时的各种情况。 它的展示还是分层展示，可以展示每个类库的名称以及版本号。 标题：如何查看 Gradle 项目的依赖作者：末日没有进行曲链接：link时间：2020-02-10声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2020/02/10/如何查看-Gradle-项目的依赖/"},{"title":"如何让 Hexo 在服务器稳定运行","text":"背景博客系统终于又搭建起来了（好一个又😶），但是每隔一段时间去访问自己的网站总是访问不到，去服务器查询 ps aux | grep hexo，发现 Hexo 进程已经挂掉了，想着自己用命令 nohup hexo s -p 8080 &gt; server.log 启动应该没问题啊，无奈也找不到停止的相关日志，所以另寻出路：找一个能实现守护进程监控服务的东西，如果服务挂掉了就自动重启。 首先想到的就是写一个 shell 脚本去进行，每隔固定时间去查询 Hexo 进程是否已经启动，没有的话重新启动。但是在实现之前我先去网上搜了一把，发现了一个神器：PM2。 PM2 是 node 的进程管理工具，利用它可以简化很多node应用管理的繁琐任务，像性能监控、自动重启等它都能实现，巧的是， Hexo 便是一个 node 应用，因此在这里我采用 PM2 来进行博客服务的自动重启功能。 步骤 首先，安装 MP2 1npm install pm2 -g 然后在我们启动服务的目录下新建一个 js 脚本文件：hexo-auto.js，内容如下： 123456var exec = require(&apos;child_process&apos;).exec;var cmd = &apos;nohup hexo s -p 8080 &gt;&gt; server.log &amp;&apos;;exec(cmd, function(error, stdout, stderr) { process.exit(0);}); 最后，执行命令：pm2 start hexo-auto.js，当页面出现以下内容时，表示我们成功了。 图中所示表示的是我们在后台 fork 了一个子进程来运行 Hexo 服务，当 Hexo 进程退出时，子进程也随之退出。PM2 监控到之后会自动重启该进程。 常用的 PM2 命令 查看进程状态 1pm2 list 停止应用 1pm2 stop id|name|all|json|stdin 其中，all 会将所有应用终止；id 为 pm2 list 查询出来的 id，name 为 pm2 list 查询出来的 name。其余两个暂时还不清楚。 重启应用 1pm2 restart id|name|all|json|stdin 参数含义同 pm2 stop 删除应用 1pm2 delete name|id|script|all|json|stdin 参数含义同 pm2 stop 查看某个应用的信息 1pm2 describe name|id 参数含义同 pm2 stop 后续问题今天，运行 pm2 时出现如下报错： 12345............npm ERR! peer dep missing: eslint@&gt;= 4.12.1, required by babel-eslint@10.0.1npm ERR! peer dep missing: acorn@^6.0.0, required by acorn-jsx@5.0.1 看错误原因是缺少 eslint 依赖，执行以下命令安装即可： 12npm install eslint@&gt;=4.12.1npm install acorn@^6.0.0","link":"/2019/06/09/如何让-Hexo-稳定运行/"},{"title":"常用 Linux 命令整理 - 账户相关","text":"Linux 是我们在开发工作中必不可少的技能了，部署、维护应用都需要懂一些 Linux 命令，现将自己常用的 Linux 命令整理一下，不定期补充更新，以供用时方便查找。 账户相关 查看当前机器的账户 123head -n 4 /etc/passwdcat /etc/passwd /etc/passwd 中存储了用户信息 显示如下： 1root:x:0:0:root:/root:/bin/bash root: 账号名称 x: 密码（早期用户密码存放在此字段，现在存放在 /etc/shadow 中） 0: UID, 0 为系统管理员（不一定只有 root 有） 0: GID root: 用户信息说明栏 /root: 家目录（默认用户家目录在 /home/yourIDname） /bin/bash: Shell 增加用户 1useradd USER_NAME 同时指定目录 1useradd -d /data/USER_NAME -m USER_NAME 设定密码 1passwd USER_NAME 删除用户 1userdel USER_NAME 显示用户信息 1id USER_NAME 增加 GROUP 组 1groupadd GROUP 增加用户 USER_NAME 同时将 USER_NAME 添加到组 GROUP 1useradd -g GROUP USER_NAME 修改组名 1groupmod -n GROUP GROUP_1 修改用户名 1usermod -l USER_NAME USER_NAME_1 查看当前用户所属组 1groups 让用户 USER_NAME 隶属于多个组 123usermod -g GROUP_1[,GROUP_2,...] USER_NAMEusermod -G GROUP_1[,GROUP_2,...] USER_NAME g 是覆盖，G是添加。 检查非 root 用户账号是否过期（包括密码） 1chage -l USER_NAME 修改用户的密码有效期 1chage -M 365 USER_NAME 修改 USER_NAME 的密码有效期为 365 天 一键创建用户名并设置组以及密码 123groupadd mg --gid 1028useradd -u 1028 -G wheel -g mg mgecho &apos;qazxsw&apos; | passwd --stdin mg","link":"/2019/07/09/常用-Linux-命令整理/"},{"title":"常用开发工具百度云下载链接","text":"MySQL 8 https://pan.baidu.com/s/1amqNL3_5Y5IIDSRjWGm3SA 密码:m2ru 标题：title作者：末日没有进行曲链接：link时间：2019-07-11声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/12/常用开发工具百度云下载链接/"},{"title":"玩转 Spring - 利用 Gradle 使用 Spring","text":"本节我们介绍下如何使用 Gradle 来搞定 Spring 依赖。 基本的 Spring 依赖Spring 设计的非常巧妙，它的各个模块都是独立的，我们在使用其中一个模块的时候基本不需要依赖其他的模块。例如，基础的 Spring Context 不需要和 Spring 的 Persistence 持久化库 以及 MVC 库一起使用。 如果我们想使用最基本的 Spring - Context，只需要加入以下依赖： 123dependencies { compile 'org.springframework:spring-context:5.1.8.RELEASE'} spring-context 依赖定义了真正的 Spring 注入容器，它包含了一丢丢依赖项：spring-core, spring-expression, spring-aop 以及 spring-beans。这些依赖支持一些核心的 Spring 技术，以此增强了 Spring 容器的能力。这些核心技术包括：核心的 Spring 程序，Spring 表达式语言（SpELl），支持面向切面编程以及 JavaBeans 技术。 实际上，我们是在运行时范围中定义了依赖关系 - 这可以确保我们对于任何特定的 Spring API 没有编译时依赖性。对于一些更高级的用例，我们可以从一些特定的 Spring 依赖项中删除运行时范围，但是对于一般的项目来说，我们不需要这么做，这样可以充分利用 Spring 的便捷性。 从 Spring 3.2 版本开始，我们便不需要定义 CGLIB （一个强大的工具，可以在运行时依赖反射等扩展 Java 类与实现 Java 接口）依赖了。它已经被直接集成到 spring-core Jar 包中了。 使用 Spring Persistence 持久化对于 Spring Persistence 持久化，主要是使用 spring-orm 依赖。 123dependencies { compile 'org.springframework:spring-orm:5.1.8.RELEASE'} 这个依赖包括 Hibernate 和 JPA，例如 HibernateTemplate 和JpaTemplate，还有一些额外的与持久性相关的依赖项：spring-jdbc 和 spring-tx 。 JDBC 数据访问依赖定义了对 Spring JDBC 的支持以及 JdbcTemplate，spring-tx 则提供了非常灵活的事务管理。 使用 Spring MVC想要获得 Spring Web 和 Servlet 的支持，除了上面的核心依赖以外，还需要在 build.gradle 中加入两个依赖： 12345dependencies { ... compile 'org.springframework:spring-web:5.1.8.RELEASE' compile 'org.springframework:spring-webmvc:5.1.8.RELEASE'} spring-web 依赖中包含对于 Servlet 和 Portlet 环境中通用的 web 工具支持，spring-webmvc 使得在 Servlet 环境中能够使用 MVC。 由于spring-webmvc将spring-web作为依赖项，因此在使用spring-webmvc时不需要明确定义spring-web。 因为 spring-webmvc 将 spring-web 作为依赖项，因此如果引用了 spring-webmvc 就不需要明确定义 spring-web 依赖了。 使用 Spring Security对于 Spring Security 的依赖，我们后面专门用一篇文章来讨论下。 使用 Spring TestSpring Test 框架可以使用以下的依赖项导入： 12345dependencies { ... compile 'org.springframework:spring-test:5.1.8.RELEASE' ...} 从Spring 3.2开始，Spring MVC Test项目作为github上的独立项目开始，已经包含在核心测试框架中 - 因此包含弹簧测试依赖性就足够了。 在最早以前 Spring MVC Test 项目是作为一个独立的项目在 GitHub 上发布的，但是从 Spring 3.2 开始，它已经放入核心的 Test 框架中了，因此如果我们要使用 Spring MVC Test，只要引入 spring-test 就足够了。 如果你还在使用 Spring 3.1 以及更低版本的 Spring，之前那些旧的依赖仍然可以使用，并且它们和现在的新框架相差不大。但是，这些依赖已经不在 Maven Central 上维护了，使用时可能需要添加自定义的存储库。 使用 Spring Milestones 版本Spring 的版本发布是托管在 Maven Central 上的，如果我们的项目需要使用 Spring 的里程碑版本，则需要将自定义的 Spring 存储库添加到依赖项中。 12345repositories { maven { url = 'http://repo.spring.io/milestone' }} 定义存储库后，我们的项目就可以使用 Spring 的里程碑版本了： 12dependencies { compile 'org.springframework:spring-context:3.2.0.RC2' 使用 Spring Snapshot 版本和 Milesones 一样，Snapshot 版本也定义在一个仓库中： 12345repositories { maven { url = 'http://repo.spring.io/snapshot' }} 定义存储库后，我们的项目就可以使用 Spring 的 Snapshot 版本了： 12dependencies { compile 'org.springframework:spring-context:4.0.3.BUILD-SNAPSHOT' 结语本篇文章我们讨论了利用 Gradle 使用 Spring 的一些细节。当然，我们只介绍了一些重要的依赖项，Spring 还有很多其他的依赖项值的我们使用学习，后面我们将一起来学习 Spring 依赖库的使用。 标题：玩转 Spring - 利用 Gradle 使用 Spring作者：末日没有进行曲链接：https://dengkaiting.com/2019/07/11/玩转-Spring-使用-Gradle-操作-Spring/时间：2019-07-11声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/11/玩转 Spring - 利用 Gradle 使用 Spring/"},{"title":"玩转 Spring - Spring Hibernate 使用","text":"本篇文章我们介绍如何使用 Spring 设置 Hibernate 以及 MySQL。我们会介绍两种方式：使用 XML 文件和 Java 配置。 Java Spring 配置 Hibernate使用 Spring 和 Java 配置设置 Hibernate 非常简单。 12 标题：[title](https://dengkaiting.com/2019/07/12/玩转 Spring - Spring Hibernate 使用/)作者：末日没有进行曲链接：[https://dengkaiting.com/2019/07/12/玩转 Spring - Spring Hibernate 使用/](https://dengkaiting.com/2019/07/12/玩转 Spring - Spring Hibernate 使用/)时间：2019-07-11声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/07/12/玩转-Spring-Spring-Hibernate-使用/"},{"title":"离职小纪","text":"第一次离职，作诗纪念。 人生无定准，逐风落尘埃。入宁未四载，历历君莫猜。求学于河海，归江尺泽鲵。咪咕始涉世，作事月廿一。历经多初次，长成犹怨咨。试问三六九，执念贪嗔痴。追忆不重现，凡世难再逢。此应互勉励，寺远亦行僧。","link":"/2019/03/22/离职小纪/"},{"title":"简单的登录服务器脚本（不用每次输入密码）","text":"记录一个简单的登录服务器脚本（不用每次输入密码） 1234567891011#!/bin/bash# usage: sh auto_login.sh 1.2.3.4instance=$1echo $instanceif [[ -z \"$instance\" ]]; then #statements echo \"instance is null\" exitfisshpass -p **pwd** ssh -o StrictHostKeyChecking=no tryking@$instance 标题：Title作者：末日没有进行曲链接：link时间：2019-04-28声明：本博客所有文章均采用 CC BY-NC-SA 4.0 许可协议，转载请注明出处。","link":"/2019/04/28/简单的登录服务器脚本（不用每次输入密码）/"}],"tags":[{"name":"感悟","slug":"感悟","link":"/tags/感悟/"},{"name":"Bootstrap","slug":"Bootstrap","link":"/tags/Bootstrap/"},{"name":"前端","slug":"前端","link":"/tags/前端/"},{"name":"Gradle","slug":"Gradle","link":"/tags/Gradle/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Json Schema","slug":"Json-Schema","link":"/tags/Json-Schema/"},{"name":"API","slug":"API","link":"/tags/API/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"生活","slug":"生活","link":"/tags/生活/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"墙","slug":"墙","link":"/tags/墙/"},{"name":"Hexo blog","slug":"Hexo-blog","link":"/tags/Hexo-blog/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"诗","slug":"诗","link":"/tags/诗/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"前端","slug":"前端","link":"/categories/前端/"},{"name":"Gradle","slug":"Gradle","link":"/categories/Gradle/"},{"name":"生活","slug":"生活","link":"/categories/生活/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Shell","slug":"Shell","link":"/categories/Shell/"},{"name":"Tools","slug":"Tools","link":"/categories/Tools/"},{"name":"感悟","slug":"感悟","link":"/categories/感悟/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"}]}